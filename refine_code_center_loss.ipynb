{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d7f7cb-c1e6-4732-8de7-b84f606b83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87c303a-de26-4231-bcf3-ba9d34c2ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attn import FixedPositionalEncoding, LearnablePositionalEncoding, TemporalEmbedding, MultiheadAttention, Decoder\n",
    "from src.loss import ContrastiveLoss, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f080cf6a-e407-41a5-bf76-d19d5764212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d3a28c0-eb82-4c52-b08a-b63964ada9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983ebd7f-7e8f-415b-9237-c3c452239b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/notebook/shared/MIMIC-IV'\n",
    "with open(os.path.join(path, 'dict_types_nomedi_mimic_240408_clinic_3_years.pkl'), 'rb') as f:\n",
    "    dtype_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(os.path.join('./data', 'preprocessed_nomedi_240423_clinic_3_years.pkl'), 'rb') as f:\n",
    "    data_dict_d = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "remain_year_clinical = pd.read_csv(os.path.join(path, \"240408_remain_year_clinical_diag_seq_4.csv\"))\n",
    "del remain_year_clinical['clinical_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8197cba0-2022-4a2a-8245-9a884f3c5386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8037/8037 [00:00<00:00, 524720.53it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "code_labels = []\n",
    "length_list = []\n",
    "clinical_labels = []\n",
    "code_length_list = []\n",
    "for sample_id, visits in tqdm(data_dict_d.items()):\n",
    "    # 레이블 추가\n",
    "    label = visits['label']\n",
    "    code_label = visits['code_label']\n",
    "    clinical_label = visits['clinical_label']\n",
    "    labels.append(label)\n",
    "    code_labels.append(code_label)\n",
    "    clinical_labels.append(clinical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c548b83-cdf5-4d39-a53e-a5600c0cf3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8037"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(data_dict_d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b640a5d0-b37e-494f-8298-afc7e322bb43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8037"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720df7f0-aaeb-4dfe-8381-f8afbb65a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, train_y, test_y = train_test_split(list(data_dict_d.keys()), labels, test_size=0.1, random_state=777, stratify=labels)\n",
    "train_indices, valid_indices, valid_y, valid_y = train_test_split(train_indices, train_y, test_size=(len(test_indices)/len(train_indices)), random_state=777, stratify=train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3346904-0cf4-430e-b7e8-0d1fbf757398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6429/6429 [00:00<00:00, 1365809.68it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1129343.74it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1112576.84it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "valid_data = {}\n",
    "test_data = {}\n",
    "for sample in tqdm(train_indices):\n",
    "    train_data[sample] = data_dict_d[sample]\n",
    "\n",
    "for sample in tqdm(valid_indices):\n",
    "    valid_data[sample] = data_dict_d[sample]\n",
    "\n",
    "for sample in tqdm(test_indices):\n",
    "    test_data[sample] = data_dict_d[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5fa78d19-7b7e-476b-b9d4-9fad9677f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(train_indices)].reset_index(drop=True)\n",
    "valid_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(valid_indices)].reset_index(drop=True)\n",
    "test_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(test_indices)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01363a8-4a8e-4768-ae31-0b8e352aeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, clinical_df, scaler, mode='train'):       \n",
    "        self.keys = list(data.keys())  # 딕셔너리의 키 목록 저장\n",
    "        self.data = data  # 딕셔너리에서 데이터만 추출하여 저장\n",
    "        self.scaler = scaler\n",
    "        if mode == 'train':\n",
    "            scaled_data = self.scaler.fit_transform(clinical_df.iloc[:, 2:])\n",
    "            scaled_clinical_df = pd.DataFrame(scaled_data, columns = clinical_df.iloc[:, 2:].columns)\n",
    "            self.scaled_clinical_df = pd.concat([clinical_df.iloc[:, :2], scaled_clinical_df], axis=1)\n",
    "        else:\n",
    "            scaled_data = self.scaler.transform(clinical_df.iloc[:, 2:])\n",
    "            scaled_clinical_df = pd.DataFrame(scaled_data, columns = clinical_df.iloc[:, 2:].columns)\n",
    "            self.scaled_clinical_df = pd.concat([clinical_df.iloc[:, :2], scaled_clinical_df], axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x는 현재 방문까지의 모든 방문 데이터, y는 다음 방문 데이터\n",
    "        padding_temp = torch.zeros((1, len(self.data[self.keys[idx]]['code_index'][0])), dtype=torch.long)\n",
    "        \n",
    "        origin_visit = torch.tensor(self.data[self.keys[idx]]['code_index'], dtype=torch.long)\n",
    "        origin_mask = torch.tensor(self.data[self.keys[idx]]['seq_mask'], dtype=torch.long)\n",
    "        origin_mask_final = torch.tensor(self.data[self.keys[idx]]['seq_mask_final'], dtype=torch.long)\n",
    "        origin_mask_code = torch.tensor(self.data[self.keys[idx]]['seq_mask_code'], dtype=torch.long)\n",
    "        \n",
    "        next_visit = torch.cat((origin_visit[1:], padding_temp), dim=0)\n",
    "        next_mask =torch.cat((origin_mask[1:], torch.tensor([0], dtype=torch.long)), dim=0)\n",
    "        next_mask_code = torch.cat((origin_mask_code[1:], padding_temp), dim=0)\n",
    "        \n",
    "        clinical_data = self.scaled_clinical_df.loc[self.scaled_clinical_df['subject_id'] == self.keys[idx], self.scaled_clinical_df.columns[2:]].values\n",
    "        clinical_data = torch.tensor(clinical_data, dtype=torch.float)\n",
    "        visit_index = torch.tensor(self.data[self.keys[idx]]['year_onehot'], dtype=torch.long)\n",
    "        last_visit_index = torch.tensor(self.data[self.keys[idx]]['last_year_onehot'], dtype=torch.float)\n",
    "        time_feature = torch.tensor(self.data[self.keys[idx]]['time_feature'], dtype=torch.long)\n",
    "        label_per_sample = self.data[self.keys[idx]]['label']\n",
    "        key_per_sample = self.keys[idx]  # 해당 샘플의 키\n",
    "        # 키 값도 함께 반환\n",
    "        return {'sample_id': key_per_sample, 'origin_visit': origin_visit, 'next_visit': next_visit,\\\n",
    "                'origin_mask': origin_mask, 'origin_mask_final': origin_mask_final, 'next_mask': next_mask, \\\n",
    "                'origin_mask_code': origin_mask_code, 'next_mask_code': next_mask_code, 'clinical_data': clinical_data, \\\n",
    "                'visit_index': visit_index, 'last_visit_index': last_visit_index, 'time_feature': time_feature, \\\n",
    "                'label': label_per_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "120bf928-219b-4804-89e2-0dc48b9c10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dataset = CustomDataset(train_data, train_clinical, scaler, mode='train')\n",
    "valid_dataset = CustomDataset(valid_data, valid_clinical, scaler, mode='valid')\n",
    "test_dataset = CustomDataset(test_data, test_clinical, scaler, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aee0bde0-cf5b-4361-8d71-185d3b634674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8e855fe-f078-479c-8774-1ca3b204724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CenterLoss(nn.Module):\n",
    "    def __init__(self, num_classes=2, feat_dim=128, device='cuda:0'):\n",
    "        super(CenterLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.feat_dim = feat_dim\n",
    "        self.device = device\n",
    "        self.centers = nn.Parameter(torch.randn(self.num_classes, self.feat_dim).to(self.device))\n",
    "        \n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: feature matrix with shape (batch_size, feat_dim).\n",
    "            labels: ground truth labels with shape (batch_size).\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        distmat = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(batch_size, self.num_classes) + \\\n",
    "                  torch.pow(self.centers, 2).sum(dim=1, keepdim=True).expand(self.num_classes, batch_size).t()\n",
    "\n",
    "        distmat.addmm_(x, self.centers.t(), beta = 1, alpha = -2,)\n",
    "\n",
    "        classes = torch.arange(self.num_classes).long().to(self.device)\n",
    "        labels = labels.unsqueeze(1).expand(batch_size, self.num_classes)\n",
    "        mask = labels.eq(classes.expand(batch_size, self.num_classes))\n",
    "\n",
    "        dist = distmat * mask.float()\n",
    "        loss = dist.clamp(min=1e-12, max=1e+12).sum() / batch_size\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48204350-6716-4234-8955-fdd6643412fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, code_size, ninp, nhead, nhid, nlayers, dropout=0.5, device='cuda:0', pe='fixed'):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.ninp = ninp  # 축소된 차원 및 Transformer 입력 차원\n",
    "        self.device = device\n",
    "        # 차원 축소를 위한 선형 레이어\n",
    "        self.pre_embedding = nn.Embedding(code_size, self.ninp)\n",
    "        self.pe = pe\n",
    "        if self.pe == 'fixed':\n",
    "            self.pos_encoder = FixedPositionalEncoding(ninp, dropout)\n",
    "        elif self.pe == 'time_feature':\n",
    "            self.pos_encoder = TemporalEmbedding(ninp, embed_type='embed', dropout=dropout)\n",
    "        else:\n",
    "            self.pos_encoder = LearnablePositionalEncoding(ninp, dropout)\n",
    "            \n",
    "        self.transformer_decoder = Decoder(ninp, nhead, nhid, nlayers, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ninp, bias=False)  # 최종 출력 차원을 설정 (여기서는 ninp로 설정)\n",
    "        self.classification_layer = nn.Linear(ninp * 2, 2)\n",
    "        self.clinical_transform = nn.Linear(18, ninp) \n",
    "        self.cross_attn = MultiheadAttention(ninp, nhead, dropout=0.3)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.pre_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.xavier_uniform_(self.classification_layer.weight)\n",
    "    \n",
    "    def forward(self, batch_data):\n",
    "        # 차원 축소\n",
    "        origin_visit = batch_data['origin_visit'].to(self.device)\n",
    "        next_visit = batch_data['next_visit'].to(self.device)\n",
    "        clinical_tensor = batch_data['clinical_data'].to(self.device)\n",
    "        mask_code = batch_data['origin_mask_code'].unsqueeze(3).to(self.device)\n",
    "        next_mask_code = batch_data['next_mask_code'].unsqueeze(3).to(self.device)\n",
    "        mask_final = batch_data['origin_mask_final'].unsqueeze(2).to(self.device)\n",
    "        mask_final_year = batch_data['last_visit_index'].to(self.device)\n",
    "\n",
    "                \n",
    "        origin_visit_emb = (self.pre_embedding(origin_visit) * mask_code).sum(dim=2)\n",
    "        next_visit_emb = (self.pre_embedding(next_visit) * next_mask_code).sum(dim=2)\n",
    "        # 위치 인코딩 및 Transformer 디코더 적용\n",
    "        if self.pe == 'time_feature':\n",
    "            time_feature = batch_data['time_feature'].to(self.device)\n",
    "            src = self.pos_encoder(origin_visit_emb, time_feature)\n",
    "        else:\n",
    "            src = self.pos_encoder(origin_visit_emb)\n",
    "        \n",
    "        seq_len = src.shape[1]\n",
    "        src_mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.uint8, device=self.device), diagonal=1)\n",
    "        output = self.transformer_decoder(src, attention_mask=src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        output_batch, output_visit_num, output_dim = output.size()\n",
    "        next_visit_output_batch, next_visit_output_num, next_visit_output_dim = next_visit_emb.size()\n",
    "        \n",
    "        # print(output[:, :torch.,:])\n",
    "        temp_output = output.reshape(-1, output_dim)\n",
    "        temp_next_visit = next_visit_emb.reshape(-1, next_visit_output_dim)\n",
    "        final_visit = (output * mask_final).sum(dim=1)\n",
    "        year_emb = torch.bmm(output.transpose(1,2), mask_final_year).transpose(1,2)[:,:2,:]\n",
    "        \n",
    "        transformed_clinical = self.clinical_transform(clinical_tensor)\n",
    "        mixed_output, mixed_cross_attn = self.cross_attn(year_emb, transformed_clinical, transformed_clinical)\n",
    "        mixed_output = mixed_output[:,-1,:]\n",
    "\n",
    "        mixed_final_emb = torch.cat((final_visit, mixed_output), dim=-1)\n",
    "        classification_result = self.classification_layer(mixed_final_emb)    \n",
    "        return temp_output, temp_next_visit, classification_result, final_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5890489-1f23-4a48-9e8b-73fbe5f90ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "ninp = 64\n",
    "nhid = 256\n",
    "nlayer = 6\n",
    "model_name = 'with_center_total_label'\n",
    "pe = 'time_feature'\n",
    "gamma = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e25eb9d-006d-49ca-99e6-228e7d7414ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1 = CustomTransformerModel(len(dtype_dict), ninp=ninp, nhead=8, nhid=nhid, nlayers=nlayer, dropout=0.1, device=device, pe=pe).to(device)\n",
    "# model_2 = CustomTransformerModel(len(dtype_dict), ninp=ninp, nhead=8, nhid=nhid, nlayers=nlayer, dropout=0.6, device=device, pe='fixed').to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(2, gamma=gamma)\n",
    "# cosine_loss = CosineSimilarityLoss()\n",
    "cosine_embedding_loss = nn.CosineEmbeddingLoss()\n",
    "# const_loss = ContrastiveLoss(temperature=0.05)\n",
    "center_loss = CenterLoss(num_classes=2, feat_dim=ninp, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4143c27e-cff0-4359-8cbd-d5ef05e6ec16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Total loss: 217.4407 , cos_loss :  0.999 , classification_loss : 0.3176 , center_loss : 43.2248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<06:13,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , valid loss: 87.3244 , cos_loss :  0.9908 , classification_loss : 0.2171 , center_loss : 17.2233\n",
      "Accuracy: 0.9129 , AUC:  0.5515 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 2 , Total loss: 79.9017 , cos_loss :  0.9831 , classification_loss : 0.2164 , center_loss : 15.7405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:07<05:53,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 , valid loss: 73.2042 , cos_loss :  0.9743 , classification_loss : 0.2054 , center_loss : 14.4049\n",
      "Accuracy: 0.9129 , AUC:  0.5525 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 3 , Total loss: 76.5398 , cos_loss :  0.9671 , classification_loss : 0.2098 , center_loss : 15.0726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:10<05:41,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 , valid loss: 72.4654 , cos_loss :  0.9594 , classification_loss : 0.1965 , center_loss : 14.2619\n",
      "Accuracy: 0.9129 , AUC:  0.6165 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 4 , Total loss: 75.0756 , cos_loss :  0.9545 , classification_loss : 0.2092 , center_loss : 14.7824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:14<05:37,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 , valid loss: 71.322 , cos_loss :  0.9493 , classification_loss : 0.2004 , center_loss : 14.0344\n",
      "Accuracy: 0.9129 , AUC:  0.5925 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 5 , Total loss: 74.3799 , cos_loss :  0.9459 , classification_loss : 0.2053 , center_loss : 14.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:17<05:29,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 , valid loss: 71.3309 , cos_loss :  0.9422 , classification_loss : 0.1999 , center_loss : 14.0377\n",
      "Accuracy: 0.9129 , AUC:  0.5855 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 6 , Total loss: 73.3742 , cos_loss :  0.9402 , classification_loss : 0.2023 , center_loss : 14.4463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:20<05:23,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 , valid loss: 71.1723 , cos_loss :  0.9374 , classification_loss : 0.199 , center_loss : 14.0072\n",
      "Accuracy: 0.9129 , AUC:  0.6007 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 7 , Total loss: 75.156 , cos_loss :  0.936 , classification_loss : 0.2041 , center_loss : 14.8032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:24<05:20,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 , valid loss: 71.2328 , cos_loss :  0.9339 , classification_loss : 0.1962 , center_loss : 14.0205\n",
      "Accuracy: 0.9129 , AUC:  0.6144 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 8 , Total loss: 74.6683 , cos_loss :  0.9331 , classification_loss : 0.2051 , center_loss : 14.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:27<05:16,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 , valid loss: 71.2054 , cos_loss :  0.9312 , classification_loss : 0.197 , center_loss : 14.0154\n",
      "Accuracy: 0.9129 , AUC:  0.6199 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 9 , Total loss: 73.506 , cos_loss :  0.9303 , classification_loss : 0.2017 , center_loss : 14.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:31<05:13,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 , valid loss: 71.0503 , cos_loss :  0.9291 , classification_loss : 0.1973 , center_loss : 13.9848\n",
      "Accuracy: 0.9129 , AUC:  0.607 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 10 , Total loss: 73.4885 , cos_loss :  0.9288 , classification_loss : 0.1987 , center_loss : 14.4722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:34<05:08,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 , valid loss: 70.9978 , cos_loss :  0.9274 , classification_loss : 0.197 , center_loss : 13.9747\n",
      "Accuracy: 0.9129 , AUC:  0.63 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 11 , Total loss: 73.6971 , cos_loss :  0.9274 , classification_loss : 0.1988 , center_loss : 14.5142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:38<05:06,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 , valid loss: 70.8228 , cos_loss :  0.9261 , classification_loss : 0.1937 , center_loss : 13.9406\n",
      "Accuracy: 0.9129 , AUC:  0.6463 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 12 , Total loss: 74.31 , cos_loss :  0.9264 , classification_loss : 0.1974 , center_loss : 14.6373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:41<05:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 , valid loss: 70.8109 , cos_loss :  0.9251 , classification_loss : 0.1951 , center_loss : 13.9381\n",
      "Accuracy: 0.9129 , AUC:  0.6444 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 13 , Total loss: 73.3334 , cos_loss :  0.9253 , classification_loss : 0.1945 , center_loss : 14.4427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:45<05:07,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 , valid loss: 70.3343 , cos_loss :  0.9242 , classification_loss : 0.1933 , center_loss : 13.8434\n",
      "Accuracy: 0.9129 , AUC:  0.6471 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 14 , Total loss: 72.4574 , cos_loss :  0.9245 , classification_loss : 0.1881 , center_loss : 14.269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:48<05:06,  3.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 , valid loss: 67.4636 , cos_loss :  0.924 , classification_loss : 0.1798 , center_loss : 13.272\n",
      "Accuracy: 0.9129 , AUC:  0.7131 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 15 , Total loss: 66.3395 , cos_loss :  0.9263 , classification_loss : 0.1649 , center_loss : 13.0496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:52<05:07,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 , valid loss: 57.261 , cos_loss :  0.9332 , classification_loss : 0.1483 , center_loss : 11.2359\n",
      "Accuracy: 0.9415 , AUC:  0.7415 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 16 , Total loss: 54.0156 , cos_loss :  0.9471 , classification_loss : 0.1426 , center_loss : 10.5852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:56<05:01,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 , valid loss: 52.3937 , cos_loss :  0.9558 , classification_loss : 0.1477 , center_loss : 10.258\n",
      "Accuracy: 0.9415 , AUC:  0.7634 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 17 , Total loss: 50.4412 , cos_loss :  0.9517 , classification_loss : 0.1419 , center_loss : 9.8695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:59<04:52,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 , valid loss: 49.7297 , cos_loss :  0.9522 , classification_loss : 0.1457 , center_loss : 9.7264\n",
      "Accuracy: 0.9415 , AUC:  0.7595 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 18 , Total loss: 48.5164 , cos_loss :  0.9503 , classification_loss : 0.1382 , center_loss : 9.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:03<04:47,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 , valid loss: 49.2026 , cos_loss :  0.9505 , classification_loss : 0.1466 , center_loss : 9.6211\n",
      "Accuracy: 0.9415 , AUC:  0.755 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 19 , Total loss: 49.0 , cos_loss :  0.9471 , classification_loss : 0.1392 , center_loss : 9.5827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:06<04:40,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 , valid loss: 48.9401 , cos_loss :  0.9482 , classification_loss : 0.1456 , center_loss : 9.5693\n",
      "Accuracy: 0.9415 , AUC:  0.7545 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 20 , Total loss: 47.9315 , cos_loss :  0.9449 , classification_loss : 0.1378 , center_loss : 9.3698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:09<04:37,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 , valid loss: 48.9974 , cos_loss :  0.9472 , classification_loss : 0.1477 , center_loss : 9.5805\n",
      "Accuracy: 0.9415 , AUC:  0.7474 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 21 , Total loss: 48.172 , cos_loss :  0.9432 , classification_loss : 0.1364 , center_loss : 9.4185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:13<04:31,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 , valid loss: 48.7349 , cos_loss :  0.9453 , classification_loss : 0.1453 , center_loss : 9.5289\n",
      "Accuracy: 0.9415 , AUC:  0.7511 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 22 , Total loss: 48.5327 , cos_loss :  0.9409 , classification_loss : 0.1367 , center_loss : 9.491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:16<04:27,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 , valid loss: 48.7324 , cos_loss :  0.9434 , classification_loss : 0.1461 , center_loss : 9.5286\n",
      "Accuracy: 0.9415 , AUC:  0.751 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 23 , Total loss: 47.9493 , cos_loss :  0.9394 , classification_loss : 0.1356 , center_loss : 9.3748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:20<04:26,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 , valid loss: 48.8139 , cos_loss :  0.9422 , classification_loss : 0.1475 , center_loss : 9.5449\n",
      "Accuracy: 0.9415 , AUC:  0.7542 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 24 , Total loss: 48.8917 , cos_loss :  0.938 , classification_loss : 0.1364 , center_loss : 9.5635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:23<04:21,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 , valid loss: 48.7632 , cos_loss :  0.9404 , classification_loss : 0.1473 , center_loss : 9.5351\n",
      "Accuracy: 0.9415 , AUC:  0.7507 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 25 , Total loss: 49.001 , cos_loss :  0.9364 , classification_loss : 0.1357 , center_loss : 9.5858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:27<04:18,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 , valid loss: 48.7694 , cos_loss :  0.9393 , classification_loss : 0.149 , center_loss : 9.5362\n",
      "Accuracy: 0.9415 , AUC:  0.7457 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 26 , Total loss: 47.7831 , cos_loss :  0.9354 , classification_loss : 0.1293 , center_loss : 9.3437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:30<04:13,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 , valid loss: 48.6795 , cos_loss :  0.9388 , classification_loss : 0.1483 , center_loss : 9.5185\n",
      "Accuracy: 0.9415 , AUC:  0.7506 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 27 , Total loss: 48.1959 , cos_loss :  0.9346 , classification_loss : 0.1333 , center_loss : 9.4256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:33<04:10,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 , valid loss: 48.6957 , cos_loss :  0.9379 , classification_loss : 0.1494 , center_loss : 9.5217\n",
      "Accuracy: 0.9415 , AUC:  0.7456 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 28 , Total loss: 47.9724 , cos_loss :  0.9338 , classification_loss : 0.132 , center_loss : 9.3813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:37<04:06,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 , valid loss: 48.8422 , cos_loss :  0.9375 , classification_loss : 0.1501 , center_loss : 9.5509\n",
      "Accuracy: 0.9415 , AUC:  0.7495 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 29 , Total loss: 47.9373 , cos_loss :  0.9332 , classification_loss : 0.131 , center_loss : 9.3746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:40<04:01,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 , valid loss: 48.6811 , cos_loss :  0.9369 , classification_loss : 0.1507 , center_loss : 9.5187\n",
      "Accuracy: 0.9415 , AUC:  0.74 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 30 , Total loss: 47.3734 , cos_loss :  0.9329 , classification_loss : 0.1284 , center_loss : 9.2624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:44<03:59,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 , valid loss: 48.688 , cos_loss :  0.9363 , classification_loss : 0.1497 , center_loss : 9.5204\n",
      "Accuracy: 0.9415 , AUC:  0.7521 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 31 , Total loss: 48.737 , cos_loss :  0.9323 , classification_loss : 0.1294 , center_loss : 9.5351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:47<03:55,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 , valid loss: 49.3047 , cos_loss :  0.9355 , classification_loss : 0.1508 , center_loss : 9.6437\n",
      "Accuracy: 0.9415 , AUC:  0.7517 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n"
     ]
    }
   ],
   "source": [
    "# 얼리 스타핑 설정\n",
    "num_epochs = 100\n",
    "patience = 40\n",
    "best_loss = float(\"inf\")\n",
    "counter = 0\n",
    "epoch_temp = 0\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_combined_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "view_total_loss = []\n",
    "view_cos_loss = []\n",
    "view_classi_loss = []\n",
    "\n",
    "cos_lambda = 1\n",
    "classi_lambda = 1\n",
    "center_lambda = 5\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model_1.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_cos_loss = 0\n",
    "    total_classi_loss = 0\n",
    "    total_center_loss = 0\n",
    "    \n",
    "    for batch_data in train_loader:\n",
    "        tr_labels = batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_1, next_visit_output_1, final_visit_classification_1, final_visit_1 = model_1(batch_data)\n",
    "        y = torch.ones(output_1.size(0), dtype=torch.float, device=device)\n",
    "        cosine_loss_mean_1 = cosine_embedding_loss(output_1, next_visit_output_1, y.to(device))\n",
    "        classification_loss_1 = criterion(final_visit_classification_1.squeeze(), tr_labels.long())\n",
    "        center_loss_1 = center_loss(final_visit_1, tr_labels.long())\n",
    "        loss = (cos_lambda * cosine_loss_mean_1) + (classi_lambda * classification_loss_1) + (center_lambda * center_loss_1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        total_cos_loss += (cosine_loss_mean_1.item())\n",
    "        total_classi_loss += (classification_loss_1.item())\n",
    "        total_center_loss += (center_loss_1.item())\n",
    "\n",
    "    # 평균 손실 계산\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_cos_loss = total_cos_loss / len(train_loader)\n",
    "    avg_classi_loss = total_classi_loss / len(train_loader)\n",
    "    avg_center_loss = total_center_loss / len(train_loader)\n",
    "\n",
    "    print(\"Epoch:\", epoch+1, \", Total loss:\", round(avg_train_loss, 4), \", cos_loss : \",\\\n",
    "          round(avg_cos_loss, 4), \", classification_loss :\",round(avg_classi_loss, 4), \n",
    "           \", center_loss :\",round(avg_center_loss, 4))\n",
    "\n",
    "    model_1.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_cos_loss = 0\n",
    "    total_val_classi_loss = 0\n",
    "    total_val_center_loss = 0\n",
    "\n",
    "    val_labels_list = []\n",
    "    val_predictions_list = []\n",
    "    val_probabilities_list = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in valid_loader:\n",
    "            val_labels = batch_data['label'].to(device)\n",
    "            val_output_1, val_next_visit_output_1, val_final_visit_classification_1, val_final_visit_1 = model_1(batch_data)\n",
    "            y_val = torch.ones(val_output_1.size(0), dtype=torch.float, device=device) \n",
    "            val_cosine_loss_mean_1 = cosine_embedding_loss(val_output_1, val_next_visit_output_1, y_val.to(device))            \n",
    "            classification_loss_val_1 = criterion(val_final_visit_classification_1.squeeze(), val_labels.long())\n",
    "            center_loss_val_1 = center_loss(val_final_visit_1, val_labels.long())\n",
    "            val_loss = (cos_lambda * val_cosine_loss_mean_1) + (classi_lambda * classification_loss_val_1) + (center_lambda * center_loss_val_1)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_cos_loss += (val_cosine_loss_mean_1.item())\n",
    "            total_val_classi_loss += (classification_loss_val_1.item())\n",
    "            total_val_center_loss += (center_loss_val_1.item())\n",
    "\n",
    "            val_probs = F.softmax(val_final_visit_classification_1)\n",
    "            val_predictions = torch.max(val_probs, 1)[1].view((len(val_labels),))\n",
    "\n",
    "            val_labels_list.extend(val_labels.view(-1).cpu().numpy())\n",
    "            val_predictions_list.extend(val_predictions.cpu().numpy())\n",
    "            \n",
    "            ########\n",
    "            val_probabilities_list.extend(val_probs[:,1].cpu().numpy())\n",
    "            ######## \n",
    "            \n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        avg_val_cos_loss = total_val_cos_loss / len(valid_loader)\n",
    "        avg_val_classi_loss = total_val_classi_loss / len(valid_loader)\n",
    "        avg_val_center_loss = total_val_center_loss / len(valid_loader)\n",
    "\n",
    "    # 성능 지표 계산\n",
    "    accuracy = accuracy_score(val_labels_list, val_predictions_list)\n",
    "    auc = roc_auc_score(val_labels_list, val_probabilities_list)\n",
    "    f1 = f1_score(val_labels_list, val_predictions_list)\n",
    "    precision = precision_score(val_labels_list,val_predictions_list)\n",
    "    recall = recall_score(val_labels_list, val_predictions_list)\n",
    "\n",
    "    print(\"Epoch:\", epoch+1, \", valid loss:\", round(avg_val_loss, 4), \", cos_loss : \",\\\n",
    "          round(avg_val_cos_loss, 4), \", classification_loss :\",round(avg_val_classi_loss, 4),\\\n",
    "          \", center_loss :\",round(avg_val_center_loss, 4))\n",
    "    print(\"Accuracy:\", round(accuracy,4), \", AUC: \", round(auc,4), \", F1: \", round(f1,4), \", Precision: \", round(precision,4), \", recall: \", round(recall,4))\n",
    "\n",
    "    current_auc = roc_auc_score(val_labels_list, val_probabilities_list)\n",
    "    current_f1 = f1_score(val_labels_list, val_predictions_list)\n",
    "    current_combined_score = current_f1\n",
    "\n",
    "    # 모델 저장 경로 설정\n",
    "    model_save_path = f'results'\n",
    "    date_dir = datetime.today().strftime(\"%Y%m%d\")\n",
    "    model_time =  datetime.today().strftime(\"%H%M%S\")\n",
    "    # 학습률과 분류 가중치를 파일명에 포함시키기 위한 문자열 포맷\n",
    "    model_filename_format = f'model_lr{lr}_classi{classi_lambda}_dim{ninp}_hid{nhid}_layer{nlayer}_epoch{{epoch}}_{{model}}_{{pe}}_{{gamma}}_{model_time}.pth'\n",
    "\n",
    "\n",
    "    # 모델 저장 폴더가 없으면 생성\n",
    "    os.makedirs(os.path.join(model_save_path, date_dir), exist_ok=True)\n",
    "\n",
    "    if current_combined_score > best_combined_score:\n",
    "        best_combined_score = current_combined_score\n",
    "        best_epoch = epoch\n",
    "        counter = 0\n",
    "        # 모델 저장 경로와 파일명을 결합하여 전체 파일 경로 생성\n",
    "        model_1_save_path = os.path.join(model_save_path, date_dir, model_filename_format.format(epoch=best_epoch, model=model_name, pe=pe, gamma=gamma))\n",
    "        # 모델 저장\n",
    "        torch.save(model_1.state_dict(), f'{model_1_save_path}')\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered at epoch {}\".format(best_epoch))\n",
    "        print(f\"Best Combined Score (AUC): {best_combined_score:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea59b82a-545f-4d8a-9d7c-b4531f4f09a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_te_loss = 0\n",
    "total_te_cos_loss = 0\n",
    "total_te_classi_loss = 0\n",
    "total_te_center_loss = 0\n",
    "\n",
    "te_labels_list = []\n",
    "te_predictions_list = []\n",
    "te_probabilities_list = []\n",
    "\n",
    "model_1_path = model_1_save_path\n",
    "model_1.load_state_dict(torch.load(model_1_path))\n",
    "model_1.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(tqdm(test_loader)):\n",
    "        te_labels = batch_data['label'].to(device)\n",
    "        te_output_1, te_next_visit_output_1, te_final_visit_classification_1, te_final_visit_1 = model_1(batch_data)\n",
    "        y_te = torch.ones(te_output_1.size(0), dtype=torch.float, device=device)\n",
    "        te_cosine_loss_mean_1 = cosine_embedding_loss(te_output_1, te_next_visit_output_1, y_te)\n",
    "        classification_loss_te_1 = criterion(te_final_visit_classification_1.squeeze(), te_labels.long())\n",
    "        center_loss_te_1 = center_loss(te_final_visit_1, te_labels.long())\n",
    "        te_loss = (cos_lambda * te_cosine_loss_mean_1) + (classi_lambda * classification_loss_te_1) + (center_lambda * center_loss_te_1)\n",
    "\n",
    "        total_te_loss += te_loss.item()\n",
    "        total_te_cos_loss += (te_cosine_loss_mean_1.item())\n",
    "        total_te_classi_loss += (classification_loss_te_1.item())\n",
    "        total_te_center_loss += (center_loss_te_1.item())\n",
    "\n",
    "        te_probs = F.softmax(te_final_visit_classification_1)\n",
    "        te_predictions = torch.max(te_probs, 1)[1].view((len(te_labels),))\n",
    "        \n",
    "        te_labels_list.extend(te_labels.view(-1).cpu().numpy())\n",
    "        te_predictions_list.extend(te_predictions.cpu().numpy())\n",
    "        te_probabilities_list.extend(te_probs[:,1].cpu().numpy())\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            test_visit_embedding = te_final_visit_1.detach().cpu().numpy()\n",
    "            test_label_numpy = te_labels.detach().cpu().numpy()\n",
    "        else:\n",
    "            add_visit_embedding = te_final_visit_1.detach().cpu().numpy()\n",
    "            add_label_numpy = te_labels.detach().cpu().numpy()\n",
    "            test_visit_embedding = np.concatenate((test_visit_embedding, add_visit_embedding), axis=0)\n",
    "            test_label_numpy = np.concatenate((test_label_numpy, add_label_numpy))\n",
    "\n",
    "    avg_te_loss = total_te_loss / len(test_loader)\n",
    "    avg_te_cos_loss = total_te_cos_loss / len(test_loader)\n",
    "    avg_te_classi_loss = total_te_classi_loss / len(test_loader)\n",
    "    avg_te_center_loss = total_te_center_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6f0995-ef57-4444-a849-49ba206cd4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 성능 지표 계산\n",
    "accuracy = accuracy_score(te_labels_list, te_predictions_list)\n",
    "auc = roc_auc_score(te_labels_list, te_probabilities_list)\n",
    "f1 = f1_score(te_labels_list, te_predictions_list)\n",
    "precision = precision_score(te_labels_list,te_predictions_list)\n",
    "recall = recall_score(te_labels_list, te_predictions_list)\n",
    "\n",
    "print(\"test loss:\", round(avg_te_loss, 4), \", cos_loss : \", round(avg_te_cos_loss, 4),\n",
    "      \", classification_loss :\",round(avg_te_classi_loss, 4), \n",
    "      \", center_loss : \", round(avg_te_center_loss, 4)\n",
    "     )\n",
    "print(\"Accuracy:\", round(accuracy,4), \", AUC: \", round(auc,4), \", F1: \", round(f1,4), \", Precision: \", round(precision,4), \", recall: \", round(recall,4))\n",
    "\n",
    "np.unique(te_labels_list,  return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3c5ee2-9d2a-4b86-8eb9-44fd847307db",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './logs'\n",
    "logs = f'model_lr{lr}_classi{classi_lambda}_dim{ninp}_hid{nhid}_layer{nlayer}_epoch{{epoch}}_{{model}}_{{pe}}_{model_time}.txt'\n",
    "os.makedirs(os.path.join(log_path, date_dir), exist_ok=True)\n",
    "\n",
    "results = [accuracy, auc, f1, precision, recall]\n",
    "cm = confusion_matrix(te_labels_list, te_predictions_list)\n",
    "with open(os.path.join(log_path, date_dir, logs.format(epoch=best_epoch, model=model_name, pe=pe)), 'w') as f:\n",
    "    f.write(logs)\n",
    "    f.write('\\n')\n",
    "    f.write(str(results))\n",
    "    f.write('\\n')\n",
    "    f.write(str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e711b386-5f88-4a9e-b41c-e49062934481",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(te_labels_list, te_predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6ab61-da34-4f72-916d-9f23ef900ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne_model = TSNE(n_components=2)\n",
    "reduction_emb = tsne_model.fit_transform(test_visit_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbd050c-3215-41bc-890a-257babf81ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for g in np.unique(test_label_numpy):\n",
    "    ix = np.where(test_label_numpy == g)\n",
    "    ax.scatter(reduction_emb[ix, 0], reduction_emb[ix, 1], label = g, s = 10)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab8b523-1d0a-41f9-a443-68cbc4052af1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
