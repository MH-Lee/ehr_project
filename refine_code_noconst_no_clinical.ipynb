{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67d7f7cb-c1e6-4732-8de7-b84f606b83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f87c303a-de26-4231-bcf3-ba9d34c2ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attn import FixedPositionalEncoding, LearnablePositionalEncoding, TemporalEmbedding, MultiheadAttention, Decoder\n",
    "from src.loss import ContrastiveLoss, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f080cf6a-e407-41a5-bf76-d19d5764212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daba1b22-ba3b-4abc-9f33-b63d1a1566a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed940215-7c3b-47e1-97ac-f07eefb03104",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/notebook/shared/MIMIC-IV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "983ebd7f-7e8f-415b-9237-c3c452239b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'dict_types_nomedi_mimic_240408_clinic_3_years.pkl'), 'rb') as f:\n",
    "    dtype_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(os.path.join('./data', 'preprocessed_nomedi_240423_clinic_3_years.pkl'), 'rb') as f:\n",
    "    data_dict_d = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ada580e-7648-4754-862f-cd41a878ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_year_clinical = pd.read_csv(os.path.join(path, \"240408_remain_year_clinical_diag_seq_4.csv\"))\n",
    "del remain_year_clinical['clinical_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3511b99c-b98a-40ae-93ca-a8573581e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12702"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c0ff63e-1a36-47cf-98ea-afe399e4a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8037/8037 [00:00<00:00, 581902.66it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "code_labels = []\n",
    "length_list = []\n",
    "clinical_labels = []\n",
    "code_length_list = []\n",
    "for sample_id, visits in tqdm(data_dict_d.items()):\n",
    "    # 레이블 추가\n",
    "    label = visits['label']\n",
    "    code_label = visits['code_label']\n",
    "    clinical_label = visits['clinical_label']\n",
    "    labels.append(label)\n",
    "    code_labels.append(code_label)\n",
    "    clinical_labels.append(clinical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "720df7f0-aaeb-4dfe-8381-f8afbb65a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, train_y, test_y = train_test_split(list(data_dict_d.keys()), labels, test_size=0.1, random_state=777, stratify=labels)\n",
    "train_indices, valid_indices, valid_y, valid_y = train_test_split(train_indices, train_y, test_size=(len(test_indices)/len(train_indices)), random_state=777, stratify=train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3346904-0cf4-430e-b7e8-0d1fbf757398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6429/6429 [00:00<00:00, 1554368.25it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1025926.50it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1079455.96it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "valid_data = {}\n",
    "test_data = {}\n",
    "for sample in tqdm(train_indices):\n",
    "    train_data[sample] = data_dict_d[sample]\n",
    "\n",
    "for sample in tqdm(valid_indices):\n",
    "    valid_data[sample] = data_dict_d[sample]\n",
    "\n",
    "for sample in tqdm(test_indices):\n",
    "    test_data[sample] = data_dict_d[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fa78d19-7b7e-476b-b9d4-9fad9677f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(train_indices)].reset_index(drop=True)\n",
    "valid_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(valid_indices)].reset_index(drop=True)\n",
    "test_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(test_indices)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c01363a8-4a8e-4768-ae31-0b8e352aeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, clinical_df, scaler, mode='train'):       \n",
    "        self.keys = list(data.keys())  # 딕셔너리의 키 목록 저장\n",
    "        self.data = data  # 딕셔너리에서 데이터만 추출하여 저장\n",
    "        self.scaler = scaler\n",
    "        if mode == 'train':\n",
    "            scaled_data = self.scaler.fit_transform(clinical_df.iloc[:, 2:])\n",
    "            scaled_clinical_df = pd.DataFrame(scaled_data, columns = clinical_df.iloc[:, 2:].columns)\n",
    "            self.scaled_clinical_df = pd.concat([clinical_df.iloc[:, :2], scaled_clinical_df], axis=1)\n",
    "        else:\n",
    "            scaled_data = self.scaler.transform(clinical_df.iloc[:, 2:])\n",
    "            scaled_clinical_df = pd.DataFrame(scaled_data, columns = clinical_df.iloc[:, 2:].columns)\n",
    "            self.scaled_clinical_df = pd.concat([clinical_df.iloc[:, :2], scaled_clinical_df], axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x는 현재 방문까지의 모든 방문 데이터, y는 다음 방문 데이터\n",
    "        padding_temp = torch.zeros((1, len(self.data[self.keys[idx]]['code_index'][0])), dtype=torch.long)\n",
    "        \n",
    "        origin_visit = torch.tensor(self.data[self.keys[idx]]['code_index'], dtype=torch.long)\n",
    "        origin_mask = torch.tensor(self.data[self.keys[idx]]['seq_mask'], dtype=torch.long)\n",
    "        origin_mask_final = torch.tensor(self.data[self.keys[idx]]['seq_mask_final'], dtype=torch.long)\n",
    "        origin_mask_code = torch.tensor(self.data[self.keys[idx]]['seq_mask_code'], dtype=torch.long)\n",
    "        \n",
    "        next_visit = torch.cat((origin_visit[1:], padding_temp), dim=0)\n",
    "        next_mask =torch.cat((origin_mask[1:], torch.tensor([0], dtype=torch.long)), dim=0)\n",
    "        next_mask_code = torch.cat((origin_mask_code[1:], padding_temp), dim=0)\n",
    "        \n",
    "        clinical_data = self.scaled_clinical_df.loc[self.scaled_clinical_df['subject_id'] == self.keys[idx], self.scaled_clinical_df.columns[2:]].values\n",
    "        clinical_data = torch.tensor(clinical_data, dtype=torch.float)\n",
    "        visit_index = torch.tensor(self.data[self.keys[idx]]['year_onehot'], dtype=torch.long)\n",
    "        last_visit_index = torch.tensor(self.data[self.keys[idx]]['last_year_onehot'], dtype=torch.float)\n",
    "        time_feature = torch.tensor(self.data[self.keys[idx]]['time_feature'], dtype=torch.long)\n",
    "        label_per_sample = self.data[self.keys[idx]]['label']\n",
    "        key_per_sample = self.keys[idx]  # 해당 샘플의 키\n",
    "        # 키 값도 함께 반환\n",
    "        return {'sample_id': key_per_sample, 'origin_visit': origin_visit, 'next_visit': next_visit,\\\n",
    "                'origin_mask': origin_mask, 'origin_mask_final': origin_mask_final, 'next_mask': next_mask, \\\n",
    "                'origin_mask_code': origin_mask_code, 'next_mask_code': next_mask_code, 'time_feature': time_feature, \\\n",
    "                'clinical_data': clinical_data, 'visit_index': visit_index, 'last_visit_index': last_visit_index, \\\n",
    "                'label': label_per_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "120bf928-219b-4804-89e2-0dc48b9c10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dataset = CustomDataset(train_data, train_clinical, scaler, mode='train')\n",
    "valid_dataset = CustomDataset(valid_data, valid_clinical, scaler, mode='valid')\n",
    "test_dataset = CustomDataset(test_data, test_clinical, scaler, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee0bde0-cf5b-4361-8d71-185d3b634674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48204350-6716-4234-8955-fdd6643412fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, code_size, ninp, nhead, nhid, nlayers, dropout=0.5, device='cuda:0', pe='fixed'):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.ninp = ninp  # 축소된 차원 및 Transformer 입력 차원\n",
    "        self.device = device\n",
    "        # 차원 축소를 위한 선형 레이어\n",
    "        self.pre_embedding = nn.Embedding(code_size, self.ninp)\n",
    "        self.pe = pe\n",
    "        if self.pe == 'fixed':\n",
    "            self.pos_encoder = FixedPositionalEncoding(ninp, dropout)\n",
    "        elif self.pe == 'time_feature':\n",
    "            self.pos_encoder = TemporalEmbedding(ninp, embed_type='embed', dropout=dropout)\n",
    "        else:\n",
    "            self.pos_encoder = LearnablePositionalEncoding(ninp, dropout)\n",
    "            \n",
    "        self.transformer_decoder = Decoder(ninp, nhead, nhid, nlayers, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ninp, bias=False)  # 최종 출력 차원을 설정 (여기서는 ninp로 설정)\n",
    "        self.classification_layer = nn.Linear(ninp, 2)\n",
    "        self.clinical_transform = nn.Linear(18, ninp) \n",
    "        self.cross_attn = MultiheadAttention(ninp, nhead, dropout=0.3)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.pre_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.xavier_uniform_(self.classification_layer.weight)\n",
    "    \n",
    "    def forward(self, batch_data):\n",
    "        # 차원 축소\n",
    "        origin_visit = batch_data['origin_visit'].to(self.device)\n",
    "        next_visit = batch_data['next_visit'].to(self.device)\n",
    "        # clinical_tensor = batch_data['clinical_data'].to(self.device)\n",
    "        mask_code = batch_data['origin_mask_code'].unsqueeze(3).to(self.device)\n",
    "        next_mask_code = batch_data['next_mask_code'].unsqueeze(3).to(self.device)\n",
    "        mask_final = batch_data['origin_mask_final'].unsqueeze(2).to(self.device)\n",
    "        mask_final_year = batch_data['last_visit_index'].to(self.device)\n",
    "                \n",
    "        origin_visit_emb = (self.pre_embedding(origin_visit) * mask_code).sum(dim=2)\n",
    "        next_visit_emb = (self.pre_embedding(next_visit) * next_mask_code).sum(dim=2)\n",
    "        # 위치 인코딩 및 Transformer 디코더 적용\n",
    "        if self.pe == 'time_feature':\n",
    "            time_feature = batch_data['time_feature'].to(self.device)\n",
    "            src = self.pos_encoder(origin_visit_emb, time_feature)\n",
    "        else:\n",
    "            src = self.pos_encoder(origin_visit_emb)\n",
    "        \n",
    "        seq_len = src.shape[1]\n",
    "        src_mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.uint8, device=self.device), diagonal=1)\n",
    "        output = self.transformer_decoder(src, attention_mask=src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        output_batch, output_visit_num, output_dim = output.size()\n",
    "        next_visit_output_batch, next_visit_output_num, next_visit_output_dim = next_visit_emb.size()\n",
    "        \n",
    "        # print(output[:, :torch.,:])\n",
    "        temp_output = output.reshape(-1, output_dim)\n",
    "        temp_next_visit = next_visit_emb.reshape(-1, next_visit_output_dim)\n",
    "        final_visit = (output * mask_final).sum(dim=1)\n",
    "        # year_emb = torch.bmm(output.transpose(1,2), mask_final_year).transpose(1,2)[:,:2,:]\n",
    "        \n",
    "        # transformed_clinical = self.clinical_transform(clinical_tensor)\n",
    "        # mixed_output, mixed_cross_attn = self.cross_attn(year_emb, transformed_clinical, transformed_clinical)\n",
    "        # mixed_output = mixed_output[:,-1,:]\n",
    "        # mixed_final_emb = torch.cat((final_visit, mixed_output), dim=-1)\n",
    "        classification_result = self.classification_layer(final_visit)    \n",
    "        return temp_output, temp_next_visit, classification_result, final_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5890489-1f23-4a48-9e8b-73fbe5f90ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "ninp = 128\n",
    "nhid = 256\n",
    "nlayer = 5\n",
    "gamma = 0.5\n",
    "model_name = 'no_center_total_label_no_clinical'\n",
    "pe = 'fixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e25eb9d-006d-49ca-99e6-228e7d7414ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1 = CustomTransformerModel(len(dtype_dict), ninp=ninp, nhead=8, nhid=nhid, nlayers=nlayer, dropout=0.1, device=device, pe=pe).to(device)\n",
    "# model_2 = CustomTransformerModel(len(dtype_dict), ninp=ninp, nhead=8, nhid=nhid, nlayers=nlayer, dropout=0.6, device=device, pe='fixed').to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(2, gamma=gamma)\n",
    "# cosine_loss = CosineSimilarityLoss()\n",
    "cosine_embedding_loss = nn.CosineEmbeddingLoss()\n",
    "# const_loss = ContrastiveLoss(temperature=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4143c27e-cff0-4359-8cbd-d5ef05e6ec16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Total loss: 1.7998 , cos_loss :  0.9805 , classification_loss : 0.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<05:38,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , valid loss: 1.4749 , cos_loss :  0.954 , classification_loss : 0.5209\n",
      "Accuracy: 0.9129 , AUC:  0.6456 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 2 , Total loss: 1.3037 , cos_loss :  0.9443 , classification_loss : 0.3594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:06<05:40,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 , valid loss: 1.1369 , cos_loss :  0.9322 , classification_loss : 0.2047\n",
      "Accuracy: 0.9129 , AUC:  0.5772 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 3 , Total loss: 1.1573 , cos_loss :  0.9287 , classification_loss : 0.2286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:10<05:33,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 , valid loss: 1.1473 , cos_loss :  0.9222 , classification_loss : 0.2251\n",
      "Accuracy: 0.9129 , AUC:  0.6424 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 4 , Total loss: 1.1396 , cos_loss :  0.9221 , classification_loss : 0.2176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:13<05:27,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 , valid loss: 1.1263 , cos_loss :  0.9181 , classification_loss : 0.2082\n",
      "Accuracy: 0.9129 , AUC:  0.6396 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 5 , Total loss: 1.1289 , cos_loss :  0.9195 , classification_loss : 0.2094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:17<05:26,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 , valid loss: 1.1195 , cos_loss :  0.9162 , classification_loss : 0.2033\n",
      "Accuracy: 0.9129 , AUC:  0.673 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 6 , Total loss: 1.1275 , cos_loss :  0.918 , classification_loss : 0.2095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:20<05:21,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 , valid loss: 1.1183 , cos_loss :  0.9152 , classification_loss : 0.2031\n",
      "Accuracy: 0.9129 , AUC:  0.6475 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 7 , Total loss: 1.1251 , cos_loss :  0.917 , classification_loss : 0.2081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:24<05:20,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 , valid loss: 1.1194 , cos_loss :  0.9145 , classification_loss : 0.2049\n",
      "Accuracy: 0.9129 , AUC:  0.6871 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 8 , Total loss: 1.128 , cos_loss :  0.9167 , classification_loss : 0.2113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:27<05:16,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 , valid loss: 1.1181 , cos_loss :  0.914 , classification_loss : 0.204\n",
      "Accuracy: 0.9129 , AUC:  0.6773 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 9 , Total loss: 1.1269 , cos_loss :  0.9158 , classification_loss : 0.2111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:30<05:13,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 , valid loss: 1.1164 , cos_loss :  0.9137 , classification_loss : 0.2028\n",
      "Accuracy: 0.9129 , AUC:  0.6801 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 10 , Total loss: 1.1277 , cos_loss :  0.9161 , classification_loss : 0.2116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:34<05:07,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 , valid loss: 1.1159 , cos_loss :  0.9134 , classification_loss : 0.2025\n",
      "Accuracy: 0.9129 , AUC:  0.6822 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 11 , Total loss: 1.1283 , cos_loss :  0.9155 , classification_loss : 0.2128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:37<05:02,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 , valid loss: 1.1187 , cos_loss :  0.9132 , classification_loss : 0.2055\n",
      "Accuracy: 0.9129 , AUC:  0.6717 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 12 , Total loss: 1.1244 , cos_loss :  0.9155 , classification_loss : 0.2089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:41<05:02,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 , valid loss: 1.1154 , cos_loss :  0.913 , classification_loss : 0.2025\n",
      "Accuracy: 0.9129 , AUC:  0.669 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 13 , Total loss: 1.1224 , cos_loss :  0.9152 , classification_loss : 0.2072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:44<04:56,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 , valid loss: 1.1161 , cos_loss :  0.9128 , classification_loss : 0.2033\n",
      "Accuracy: 0.9129 , AUC:  0.6761 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 14 , Total loss: 1.1244 , cos_loss :  0.9152 , classification_loss : 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:48<04:55,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 , valid loss: 1.1167 , cos_loss :  0.9127 , classification_loss : 0.2041\n",
      "Accuracy: 0.9129 , AUC:  0.6719 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 15 , Total loss: 1.1238 , cos_loss :  0.9151 , classification_loss : 0.2088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:51<04:51,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 , valid loss: 1.1142 , cos_loss :  0.9125 , classification_loss : 0.2017\n",
      "Accuracy: 0.9129 , AUC:  0.6697 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 16 , Total loss: 1.1234 , cos_loss :  0.9149 , classification_loss : 0.2085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:54<04:49,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 , valid loss: 1.1136 , cos_loss :  0.9124 , classification_loss : 0.2011\n",
      "Accuracy: 0.9129 , AUC:  0.6758 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 17 , Total loss: 1.1235 , cos_loss :  0.9151 , classification_loss : 0.2084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:58<04:44,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 , valid loss: 1.113 , cos_loss :  0.9123 , classification_loss : 0.2006\n",
      "Accuracy: 0.9129 , AUC:  0.6767 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 18 , Total loss: 1.1228 , cos_loss :  0.9149 , classification_loss : 0.2079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:01<04:41,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 , valid loss: 1.111 , cos_loss :  0.9123 , classification_loss : 0.1987\n",
      "Accuracy: 0.9129 , AUC:  0.6731 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 19 , Total loss: 1.1142 , cos_loss :  0.9149 , classification_loss : 0.1993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:05<04:36,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 , valid loss: 1.0944 , cos_loss :  0.9123 , classification_loss : 0.1821\n",
      "Accuracy: 0.9129 , AUC:  0.6678 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 20 , Total loss: 1.0917 , cos_loss :  0.9149 , classification_loss : 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:08<04:35,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 , valid loss: 1.0681 , cos_loss :  0.9131 , classification_loss : 0.155\n",
      "Accuracy: 0.9415 , AUC:  0.6623 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 21 , Total loss: 1.0772 , cos_loss :  0.9159 , classification_loss : 0.1612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:11<04:30,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 , valid loss: 1.0673 , cos_loss :  0.9135 , classification_loss : 0.1539\n",
      "Accuracy: 0.9415 , AUC:  0.6559 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 22 , Total loss: 1.0755 , cos_loss :  0.9156 , classification_loss : 0.1599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:15<04:29,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 , valid loss: 1.0633 , cos_loss :  0.9134 , classification_loss : 0.1498\n",
      "Accuracy: 0.9415 , AUC:  0.673 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 23 , Total loss: 1.0652 , cos_loss :  0.9157 , classification_loss : 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:18<04:24,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 , valid loss: 1.0683 , cos_loss :  0.9135 , classification_loss : 0.1548\n",
      "Accuracy: 0.9415 , AUC:  0.6709 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 24 , Total loss: 1.0665 , cos_loss :  0.9154 , classification_loss : 0.1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:22<04:19,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 , valid loss: 1.0632 , cos_loss :  0.9133 , classification_loss : 0.1499\n",
      "Accuracy: 0.9415 , AUC:  0.6771 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 25 , Total loss: 1.0647 , cos_loss :  0.9154 , classification_loss : 0.1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:25<04:17,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 , valid loss: 1.0633 , cos_loss :  0.9132 , classification_loss : 0.1501\n",
      "Accuracy: 0.9415 , AUC:  0.6762 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 26 , Total loss: 1.0634 , cos_loss :  0.9156 , classification_loss : 0.1478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:29<04:12,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 , valid loss: 1.064 , cos_loss :  0.9132 , classification_loss : 0.1508\n",
      "Accuracy: 0.9415 , AUC:  0.672 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 27 , Total loss: 1.0634 , cos_loss :  0.9154 , classification_loss : 0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:32<04:10,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 , valid loss: 1.0634 , cos_loss :  0.9131 , classification_loss : 0.1503\n",
      "Accuracy: 0.9415 , AUC:  0.6717 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 28 , Total loss: 1.0634 , cos_loss :  0.9154 , classification_loss : 0.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:35<04:05,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 , valid loss: 1.0635 , cos_loss :  0.913 , classification_loss : 0.1505\n",
      "Accuracy: 0.9415 , AUC:  0.6702 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 29 , Total loss: 1.0632 , cos_loss :  0.9152 , classification_loss : 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:39<04:09,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 , valid loss: 1.0627 , cos_loss :  0.913 , classification_loss : 0.1497\n",
      "Accuracy: 0.9415 , AUC:  0.6724 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 30 , Total loss: 1.0646 , cos_loss :  0.9153 , classification_loss : 0.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:43<04:02,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 , valid loss: 1.0629 , cos_loss :  0.9129 , classification_loss : 0.1501\n",
      "Accuracy: 0.9415 , AUC:  0.673 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 31 , Total loss: 1.0634 , cos_loss :  0.9152 , classification_loss : 0.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:46<03:57,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 , valid loss: 1.0645 , cos_loss :  0.9128 , classification_loss : 0.1517\n",
      "Accuracy: 0.9415 , AUC:  0.6743 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 32 , Total loss: 1.0665 , cos_loss :  0.9151 , classification_loss : 0.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:49<03:55,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 , valid loss: 1.0646 , cos_loss :  0.9127 , classification_loss : 0.1519\n",
      "Accuracy: 0.9415 , AUC:  0.6724 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 33 , Total loss: 1.0652 , cos_loss :  0.9151 , classification_loss : 0.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:53<03:49,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 , valid loss: 1.0648 , cos_loss :  0.9127 , classification_loss : 0.1522\n",
      "Accuracy: 0.9415 , AUC:  0.6604 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 34 , Total loss: 1.0699 , cos_loss :  0.9152 , classification_loss : 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [01:56<03:47,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 , valid loss: 1.0622 , cos_loss :  0.9125 , classification_loss : 0.1497\n",
      "Accuracy: 0.9415 , AUC:  0.674 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 35 , Total loss: 1.0664 , cos_loss :  0.915 , classification_loss : 0.1514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:00<03:46,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 , valid loss: 1.0623 , cos_loss :  0.9127 , classification_loss : 0.1495\n",
      "Accuracy: 0.9415 , AUC:  0.6705 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 36 , Total loss: 1.0647 , cos_loss :  0.9152 , classification_loss : 0.1495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:04<03:46,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 , valid loss: 1.0625 , cos_loss :  0.9126 , classification_loss : 0.1499\n",
      "Accuracy: 0.9415 , AUC:  0.6777 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 37 , Total loss: 1.0624 , cos_loss :  0.9151 , classification_loss : 0.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:07<03:39,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 , valid loss: 1.0661 , cos_loss :  0.9126 , classification_loss : 0.1534\n",
      "Accuracy: 0.9415 , AUC:  0.6659 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 38 , Total loss: 1.0651 , cos_loss :  0.915 , classification_loss : 0.1501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:10<03:34,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 , valid loss: 1.0622 , cos_loss :  0.9124 , classification_loss : 0.1498\n",
      "Accuracy: 0.9415 , AUC:  0.6805 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 39 , Total loss: 1.0626 , cos_loss :  0.9147 , classification_loss : 0.1479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:14<03:28,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 , valid loss: 1.0632 , cos_loss :  0.9125 , classification_loss : 0.1507\n",
      "Accuracy: 0.9415 , AUC:  0.6737 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 40 , Total loss: 1.0653 , cos_loss :  0.9149 , classification_loss : 0.1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [02:17<03:23,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 , valid loss: 1.0801 , cos_loss :  0.9126 , classification_loss : 0.1675\n",
      "Accuracy: 0.9415 , AUC:  0.6704 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 41 , Total loss: 1.0677 , cos_loss :  0.9151 , classification_loss : 0.1527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [02:20<03:20,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 , valid loss: 1.0622 , cos_loss :  0.9125 , classification_loss : 0.1497\n",
      "Accuracy: 0.9415 , AUC:  0.6722 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 42 , Total loss: 1.0617 , cos_loss :  0.9149 , classification_loss : 0.1468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [02:24<03:15,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 , valid loss: 1.0628 , cos_loss :  0.9124 , classification_loss : 0.1504\n",
      "Accuracy: 0.9415 , AUC:  0.6783 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 43 , Total loss: 1.0634 , cos_loss :  0.915 , classification_loss : 0.1484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:27<03:13,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 , valid loss: 1.0631 , cos_loss :  0.9124 , classification_loss : 0.1507\n",
      "Accuracy: 0.9415 , AUC:  0.6802 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 44 , Total loss: 1.0621 , cos_loss :  0.9148 , classification_loss : 0.1473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [02:30<03:09,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 , valid loss: 1.0623 , cos_loss :  0.9123 , classification_loss : 0.15\n",
      "Accuracy: 0.9415 , AUC:  0.6601 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 45 , Total loss: 1.0637 , cos_loss :  0.9148 , classification_loss : 0.1489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:34<03:06,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 , valid loss: 1.0623 , cos_loss :  0.9123 , classification_loss : 0.1499\n",
      "Accuracy: 0.9415 , AUC:  0.6672 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 46 , Total loss: 1.0695 , cos_loss :  0.9148 , classification_loss : 0.1547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [02:37<03:06,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 , valid loss: 1.0624 , cos_loss :  0.9122 , classification_loss : 0.1501\n",
      "Accuracy: 0.9415 , AUC:  0.6801 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 47 , Total loss: 1.0651 , cos_loss :  0.9147 , classification_loss : 0.1504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [02:41<03:03,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 , valid loss: 1.0619 , cos_loss :  0.9123 , classification_loss : 0.1496\n",
      "Accuracy: 0.9415 , AUC:  0.6694 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 48 , Total loss: 1.063 , cos_loss :  0.9147 , classification_loss : 0.1482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [02:45<03:03,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 , valid loss: 1.0644 , cos_loss :  0.9123 , classification_loss : 0.1521\n",
      "Accuracy: 0.9415 , AUC:  0.6735 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 49 , Total loss: 1.0636 , cos_loss :  0.9148 , classification_loss : 0.1488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [02:48<02:58,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 , valid loss: 1.0621 , cos_loss :  0.9123 , classification_loss : 0.1499\n",
      "Accuracy: 0.9415 , AUC:  0.6745 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Epoch: 50 , Total loss: 1.0631 , cos_loss :  0.915 , classification_loss : 0.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [02:52<02:59,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 , valid loss: 1.0632 , cos_loss :  0.9122 , classification_loss : 0.151\n",
      "Accuracy: 0.9415 , AUC:  0.6772 , F1:  0.4946 , Precision:  1.0 , recall:  0.3286\n",
      "Early stopping triggered at epoch 19\n",
      "Best Combined Score (AUC): 0.4946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 얼리 스타핑 설정\n",
    "num_epochs = 100\n",
    "patience = 30\n",
    "best_loss = float(\"inf\")\n",
    "counter = 0\n",
    "epoch_temp = 0\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_combined_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "view_total_loss = []\n",
    "view_cos_loss = []\n",
    "view_classi_loss = []\n",
    "\n",
    "cos_lambda = 1\n",
    "classi_lambda = 1\n",
    "const_lambda = 1\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model_1.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_cos_loss = 0\n",
    "    total_classi_loss = 0\n",
    "    total_const_loss = 0\n",
    "    # key_per_sample, origin_visit, origin_mask, origin_mask_code, origin_mask_final, next_visit, next_mask, next_mask_code, next_mask_final, label_per_sample\n",
    "    for batch_data in train_loader:\n",
    "        tr_labels = batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_1, next_visit_output_1, final_visit_classification_1, final_visit_1 = model_1(batch_data)\n",
    "        y = torch.ones(output_1.size(0), dtype=torch.float, device=device)\n",
    "        y = y.to(device)   \n",
    "        cosine_loss_mean_1 = cosine_embedding_loss(output_1, next_visit_output_1, y)\n",
    "        classification_loss_1 = criterion(final_visit_classification_1.squeeze(), tr_labels.long())\n",
    "        loss = (cos_lambda * cosine_loss_mean_1) + (classi_lambda * classification_loss_1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        total_cos_loss += (cosine_loss_mean_1.item())\n",
    "        total_classi_loss += (classification_loss_1.item())\n",
    "        # total_const_loss += train_const_loss.item()\n",
    "\n",
    "        view_total_loss.append(total_train_loss)\n",
    "        view_cos_loss.append(total_cos_loss)\n",
    "        view_classi_loss.append(total_classi_loss)\n",
    "\n",
    "    # 평균 손실 계산\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_cos_loss = total_cos_loss / len(train_loader)\n",
    "    avg_classi_loss = total_classi_loss / len(train_loader)\n",
    "\n",
    "    print(\"Epoch:\", epoch+1, \", Total loss:\", round(avg_train_loss, 4), \", cos_loss : \",\\\n",
    "          round(avg_cos_loss, 4), \", classification_loss :\",round(avg_classi_loss, 4))\n",
    "\n",
    "    model_1.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_cos_loss = 0\n",
    "    total_val_classi_loss = 0\n",
    "    total_val_const_loss = 0\n",
    "\n",
    "    val_labels_list = []\n",
    "    val_predictions_list = []\n",
    "    val_probabilities_list = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in valid_loader:\n",
    "            val_labels = batch_data['label'].to(device)\n",
    "            val_output_1, val_next_visit_output_1, val_final_visit_classification_1, val_final_visit_1 = model_1(batch_data)\n",
    "            \n",
    "            y_val = torch.ones(val_output_1.size(0), dtype=torch.float, device=device) \n",
    "            val_cosine_loss_mean_1 = cosine_embedding_loss(val_output_1, val_next_visit_output_1, y_val)\n",
    "            \n",
    "            classification_loss_val_1 = criterion(val_final_visit_classification_1.squeeze(), val_labels.long())            \n",
    "\n",
    "            val_loss = (cos_lambda * val_cosine_loss_mean_1) + (classi_lambda * classification_loss_val_1) \n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_cos_loss += (val_cosine_loss_mean_1.item())\n",
    "            total_val_classi_loss += (classification_loss_val_1.item())\n",
    "            # total_val_const_loss += val_const_loss.item()\n",
    "\n",
    "            val_probs = F.softmax(val_final_visit_classification_1)\n",
    "            val_predictions = torch.max(val_probs, 1)[1].view((len(val_labels),))\n",
    "\n",
    "            val_labels_list.extend(val_labels.view(-1).cpu().numpy())\n",
    "            val_predictions_list.extend(val_predictions.cpu().numpy())\n",
    "            \n",
    "            ########\n",
    "            val_probabilities_list.extend(val_probs[:,1].cpu().numpy())\n",
    "            ######## \n",
    "            \n",
    "            \n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        avg_val_cos_loss = total_val_cos_loss / len(valid_loader)\n",
    "        avg_val_classi_loss = total_val_classi_loss / len(valid_loader)\n",
    "\n",
    "    # 성능 지표 계산\n",
    "    accuracy = accuracy_score(val_labels_list, val_predictions_list)\n",
    "    auc = roc_auc_score(val_labels_list, val_probabilities_list)\n",
    "    f1 = f1_score(val_labels_list, val_predictions_list)\n",
    "    precision = precision_score(val_labels_list,val_predictions_list)\n",
    "    recall = recall_score(val_labels_list, val_predictions_list)\n",
    "\n",
    "    print(\"Epoch:\", epoch+1, \", valid loss:\", round(avg_val_loss, 4), \", cos_loss : \",\\\n",
    "          round(avg_val_cos_loss, 4), \", classification_loss :\",round(avg_val_classi_loss, 4))\n",
    "    print(\"Accuracy:\", round(accuracy,4), \", AUC: \", round(auc,4), \", F1: \", round(f1,4), \", Precision: \", round(precision,4), \", recall: \", round(recall,4))\n",
    "\n",
    "    current_auc = roc_auc_score(val_labels_list, val_probabilities_list)\n",
    "    current_f1 = f1_score(val_labels_list, val_predictions_list)\n",
    "    current_combined_score = current_f1\n",
    "\n",
    "    # 모델 저장 경로 설정\n",
    "    model_save_path = f'results'\n",
    "    date_dir = datetime.today().strftime(\"%Y%m%d\")\n",
    "    model_time =  datetime.today().strftime(\"%H%M%S\")\n",
    "    # 학습률과 분류 가중치를 파일명에 포함시키기 위한 문자열 포맷\n",
    "    model_filename_format = f'model_lr{lr}_classi{classi_lambda}_dim{ninp}_hid{nhid}_layer{nlayer}_epoch{{epoch}}_{{model}}_{{pe}}_{{gamma}}_{model_time}.pth'\n",
    "\n",
    "    # 모델 저장 폴더가 없으면 생성\n",
    "    os.makedirs(os.path.join(model_save_path, date_dir), exist_ok=True)\n",
    "\n",
    "    if current_combined_score > best_combined_score:\n",
    "        best_combined_score = current_combined_score\n",
    "        best_epoch = epoch\n",
    "        counter = 0\n",
    "        # 모델 저장 경로와 파일명을 결합하여 전체 파일 경로 생성\n",
    "        model_1_save_path = os.path.join(model_save_path, date_dir, model_filename_format.format(epoch=best_epoch, model=model_name, pe=pe, gamma=gamma))\n",
    "        # 모델 저장\n",
    "        torch.save(model_1.state_dict(), f'{model_1_save_path}')\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered at epoch {}\".format(best_epoch))\n",
    "        print(f\"Best Combined Score (AUC): {best_combined_score:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea59b82a-545f-4d8a-9d7c-b4531f4f09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.92it/s]\n"
     ]
    }
   ],
   "source": [
    "total_te_loss = 0\n",
    "total_te_cos_loss = 0\n",
    "total_te_classi_loss = 0\n",
    "total_te_const_loss = 0\n",
    "\n",
    "te_labels_list = []\n",
    "te_predictions_list = []\n",
    "te_probabilities_list = []\n",
    "\n",
    "model_1_path = model_1_save_path\n",
    "\n",
    "model_1.load_state_dict(torch.load(model_1_path))\n",
    "\n",
    "model_1.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_data in tqdm(test_loader):\n",
    "        te_labels = batch_data['label'].to(device)\n",
    "        te_output_1, te_next_visit_output_1, te_final_visit_classification_1, te_final_visit_1 = model_1(batch_data)\n",
    "        y_te = torch.ones(te_output_1.size(0), dtype=torch.float, device=device)\n",
    "\n",
    "        te_cosine_loss_mean_1 = cosine_embedding_loss(te_output_1, te_next_visit_output_1, y_te)\n",
    "        classification_loss_te_1 = criterion(te_final_visit_classification_1.squeeze(), te_labels.long())\n",
    "        te_loss = (cos_lambda * te_cosine_loss_mean_1) + (classi_lambda * classification_loss_te_1) \n",
    "\n",
    "        total_te_loss += te_loss.item()\n",
    "        total_te_cos_loss += (te_cosine_loss_mean_1.item())\n",
    "        total_te_classi_loss += (classification_loss_te_1.item())\n",
    "\n",
    "        te_probs = F.softmax(te_final_visit_classification_1)\n",
    "        te_predictions = torch.max(te_probs, 1)[1].view((len(te_labels),))\n",
    "        \n",
    "        te_labels_list.extend(te_labels.view(-1).cpu().numpy())\n",
    "        te_predictions_list.extend(te_predictions.cpu().numpy())\n",
    "        te_probabilities_list.extend(te_probs[:,1].cpu().numpy())\n",
    "\n",
    "    avg_te_loss = total_te_loss / len(test_loader)\n",
    "    avg_te_cos_loss = total_te_cos_loss / len(test_loader)\n",
    "    avg_te_classi_loss = total_te_classi_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f87c3121-1152-41b2-8f8c-b47b01139157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0737 , cos_loss :  0.9129 , classification_loss : 0.1607\n",
      "Accuracy: 0.9453 , AUC:  0.7131 , F1:  0.5417 , Precision:  1.0 , recall:  0.3714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([734,  70]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 성능 지표 계산\n",
    "accuracy = accuracy_score(te_labels_list, te_predictions_list)\n",
    "auc = roc_auc_score(te_labels_list, te_probabilities_list)\n",
    "f1 = f1_score(te_labels_list, te_predictions_list)\n",
    "precision = precision_score(te_labels_list,te_predictions_list)\n",
    "recall = recall_score(te_labels_list, te_predictions_list)\n",
    "\n",
    "print(\"test loss:\", round(avg_te_loss, 4), \", cos_loss : \", round(avg_te_cos_loss, 4),\n",
    "      \", classification_loss :\",round(avg_te_classi_loss, 4), \n",
    "      # \", contrastive_loss : \", round(avg_te_const_loss,4)\n",
    "     )\n",
    "print(\"Accuracy:\", round(accuracy,4), \", AUC: \", round(auc,4), \", F1: \", round(f1,4), \", Precision: \", round(precision,4), \", recall: \", round(recall,4))\n",
    "\n",
    "np.unique(te_labels_list,  return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "17655ab8-b66a-470d-ad41-efe9b5887031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'175256'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59a45dbf-6a08-401e-a279-411c1e99c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './logs'\n",
    "logs = f'model_lr{lr}_classi{classi_lambda}_dim{ninp}_hid{nhid}_layer{nlayer}_epoch{{epoch}}_{{model}}_{{pe}}_{model_time}.txt'\n",
    "os.makedirs(os.path.join(log_path, date_dir), exist_ok=True)\n",
    "\n",
    "results = [accuracy, auc, f1, precision, recall]\n",
    "cm = confusion_matrix(te_labels_list, te_predictions_list)\n",
    "with open(os.path.join(log_path, date_dir, logs.format(epoch=best_epoch, model=model_name, pe=pe)), 'w') as f:\n",
    "    f.write(logs.format(epoch=best_epoch, model=model_name, pe=pe))\n",
    "    f.write('\\n')\n",
    "    f.write(str(results))\n",
    "    f.write('\\n')\n",
    "    f.write(str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d01e7e3b-c3e6-4813-8eeb-dfc111a65c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[734,   0],\n",
       "       [ 44,  26]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(te_labels_list, te_predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb31a9c4-fe2d-45de-9c4f-9a6aa1285ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
