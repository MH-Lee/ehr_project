{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67d7f7cb-c1e6-4732-8de7-b84f606b83ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import pickle\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f87c303a-de26-4231-bcf3-ba9d34c2ae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.attn import FixedPositionalEncoding, LearnablePositionalEncoding, TemporalEmbedding, MultiheadAttention, Decoder\n",
    "from src.loss import ContrastiveLoss, FocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f080cf6a-e407-41a5-bf76-d19d5764212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daba1b22-ba3b-4abc-9f33-b63d1a1566a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "cudnn.benchmark = False\n",
    "cudnn.deterministic = True\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed940215-7c3b-47e1-97ac-f07eefb03104",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/data/notebook/shared/MIMIC-IV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "983ebd7f-7e8f-415b-9237-c3c452239b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(path, 'dict_types_nomedi_mimic_240408_clinic_3_years.pkl'), 'rb') as f:\n",
    "    dtype_dict = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "with open(os.path.join('./data', 'preprocessed_nomedi_240423_clinic_3_years.pkl'), 'rb') as f:\n",
    "    data_dict_d = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ada580e-7648-4754-862f-cd41a878ac20",
   "metadata": {},
   "outputs": [],
   "source": [
    "remain_year_clinical = pd.read_csv(os.path.join(path, \"240408_remain_year_clinical_diag_seq_4.csv\"))\n",
    "del remain_year_clinical['clinical_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3511b99c-b98a-40ae-93ca-a8573581e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12702"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c0ff63e-1a36-47cf-98ea-afe399e4a13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8037/8037 [00:00<00:00, 501422.34it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "code_labels = []\n",
    "length_list = []\n",
    "clinical_labels = []\n",
    "code_length_list = []\n",
    "for sample_id, visits in tqdm(data_dict_d.items()):\n",
    "    # 레이블 추가\n",
    "    label = visits['label']\n",
    "    code_label = visits['code_label']\n",
    "    clinical_label = visits['clinical_label']\n",
    "    labels.append(label)\n",
    "    code_labels.append(code_label)\n",
    "    clinical_labels.append(clinical_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "720df7f0-aaeb-4dfe-8381-f8afbb65a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, test_indices, train_y, test_y = train_test_split(list(data_dict_d.keys()), code_labels, test_size=0.1, random_state=777, stratify=code_labels)\n",
    "train_indices, valid_indices, valid_y, valid_y = train_test_split(train_indices, train_y, test_size=(len(test_indices)/len(train_indices)), random_state=777, stratify=train_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3346904-0cf4-430e-b7e8-0d1fbf757398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6429/6429 [00:00<00:00, 713987.88it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1036968.15it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 1057122.39it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "valid_data = {}\n",
    "test_data = {}\n",
    "for sample in tqdm(train_indices):\n",
    "    train_data[sample] = data_dict_d[sample]\n",
    "\n",
    "for sample in tqdm(valid_indices):\n",
    "    valid_data[sample] = data_dict_d[sample]\n",
    "\n",
    "for sample in tqdm(test_indices):\n",
    "    test_data[sample] = data_dict_d[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5fa78d19-7b7e-476b-b9d4-9fad9677f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(train_indices)].reset_index(drop=True)\n",
    "valid_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(valid_indices)].reset_index(drop=True)\n",
    "test_clinical = remain_year_clinical[remain_year_clinical['subject_id'].isin(test_indices)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c01363a8-4a8e-4768-ae31-0b8e352aeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, clinical_df, scaler, mode='train'):       \n",
    "        self.keys = list(data.keys())  # 딕셔너리의 키 목록 저장\n",
    "        self.data = data  # 딕셔너리에서 데이터만 추출하여 저장\n",
    "        self.scaler = scaler\n",
    "        if mode == 'train':\n",
    "            scaled_data = self.scaler.fit_transform(clinical_df.iloc[:, 2:])\n",
    "            scaled_clinical_df = pd.DataFrame(scaled_data, columns = clinical_df.iloc[:, 2:].columns)\n",
    "            self.scaled_clinical_df = pd.concat([clinical_df.iloc[:, :2], scaled_clinical_df], axis=1)\n",
    "        else:\n",
    "            scaled_data = self.scaler.transform(clinical_df.iloc[:, 2:])\n",
    "            scaled_clinical_df = pd.DataFrame(scaled_data, columns = clinical_df.iloc[:, 2:].columns)\n",
    "            self.scaled_clinical_df = pd.concat([clinical_df.iloc[:, :2], scaled_clinical_df], axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # x는 현재 방문까지의 모든 방문 데이터, y는 다음 방문 데이터\n",
    "        padding_temp = torch.zeros((1, len(self.data[self.keys[idx]]['code_index'][0])), dtype=torch.long)\n",
    "        \n",
    "        origin_visit = torch.tensor(self.data[self.keys[idx]]['code_index'], dtype=torch.long)\n",
    "        origin_mask = torch.tensor(self.data[self.keys[idx]]['seq_mask'], dtype=torch.long)\n",
    "        origin_mask_final = torch.tensor(self.data[self.keys[idx]]['seq_mask_final'], dtype=torch.long)\n",
    "        origin_mask_code = torch.tensor(self.data[self.keys[idx]]['seq_mask_code'], dtype=torch.long)\n",
    "        \n",
    "        next_visit = torch.cat((origin_visit[1:], padding_temp), dim=0)\n",
    "        next_mask =torch.cat((origin_mask[1:], torch.tensor([0], dtype=torch.long)), dim=0)\n",
    "        next_mask_code = torch.cat((origin_mask_code[1:], padding_temp), dim=0)\n",
    "        \n",
    "        clinical_data = self.scaled_clinical_df.loc[self.scaled_clinical_df['subject_id'] == self.keys[idx], self.scaled_clinical_df.columns[2:]].values\n",
    "        clinical_data = torch.tensor(clinical_data, dtype=torch.float)\n",
    "        visit_index = torch.tensor(self.data[self.keys[idx]]['year_onehot'], dtype=torch.long)\n",
    "        last_visit_index = torch.tensor(self.data[self.keys[idx]]['last_year_onehot'], dtype=torch.float)\n",
    "        time_feature = torch.tensor(self.data[self.keys[idx]]['time_feature'], dtype=torch.long)\n",
    "        label_per_sample = self.data[self.keys[idx]]['code_label']\n",
    "        key_per_sample = self.keys[idx]  # 해당 샘플의 키\n",
    "        # 키 값도 함께 반환\n",
    "        return {'sample_id': key_per_sample, 'origin_visit': origin_visit, 'next_visit': next_visit,\\\n",
    "                'origin_mask': origin_mask, 'origin_mask_final': origin_mask_final, 'next_mask': next_mask, \\\n",
    "                'origin_mask_code': origin_mask_code, 'next_mask_code': next_mask_code, 'time_feature': time_feature, \\\n",
    "                'clinical_data': clinical_data, 'visit_index': visit_index, 'last_visit_index': last_visit_index, \\\n",
    "                'label': label_per_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "120bf928-219b-4804-89e2-0dc48b9c10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "train_dataset = CustomDataset(train_data, train_clinical, scaler, mode='train')\n",
    "valid_dataset = CustomDataset(valid_data, valid_clinical, scaler, mode='valid')\n",
    "test_dataset = CustomDataset(test_data, test_clinical, scaler, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aee0bde0-cf5b-4361-8d71-185d3b634674",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=512, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48204350-6716-4234-8955-fdd6643412fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerModel(nn.Module):\n",
    "    def __init__(self, code_size, ninp, nhead, nhid, nlayers, dropout=0.5, device='cuda:0', pe='fixed'):\n",
    "        super(CustomTransformerModel, self).__init__()\n",
    "        self.ninp = ninp  # 축소된 차원 및 Transformer 입력 차원\n",
    "        self.device = device\n",
    "        # 차원 축소를 위한 선형 레이어\n",
    "        self.pre_embedding = nn.Embedding(code_size, self.ninp)\n",
    "        self.pe = pe\n",
    "        if self.pe == 'fixed':\n",
    "            self.pos_encoder = FixedPositionalEncoding(ninp, dropout)\n",
    "        elif self.pe == 'time_feature':\n",
    "            self.pos_encoder = TemporalEmbedding(ninp, embed_type='embed', dropout=dropout)\n",
    "        else:\n",
    "            self.pos_encoder = LearnablePositionalEncoding(ninp, dropout)\n",
    "            \n",
    "        self.transformer_decoder = Decoder(ninp, nhead, nhid, nlayers, dropout)\n",
    "        self.decoder = nn.Linear(ninp, ninp, bias=False)  # 최종 출력 차원을 설정 (여기서는 ninp로 설정)\n",
    "        self.classification_layer = nn.Linear(ninp, 2)\n",
    "        self.clinical_transform = nn.Linear(18, ninp) \n",
    "        self.cross_attn = MultiheadAttention(ninp, nhead, dropout=0.3)\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.pre_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.decoder.weight)\n",
    "        nn.init.xavier_uniform_(self.classification_layer.weight)\n",
    "    \n",
    "    def forward(self, batch_data):\n",
    "        # 차원 축소\n",
    "        origin_visit = batch_data['origin_visit'].to(self.device)\n",
    "        next_visit = batch_data['next_visit'].to(self.device)\n",
    "        # clinical_tensor = batch_data['clinical_data'].to(self.device)\n",
    "        mask_code = batch_data['origin_mask_code'].unsqueeze(3).to(self.device)\n",
    "        next_mask_code = batch_data['next_mask_code'].unsqueeze(3).to(self.device)\n",
    "        mask_final = batch_data['origin_mask_final'].unsqueeze(2).to(self.device)\n",
    "        mask_final_year = batch_data['last_visit_index'].to(self.device)\n",
    "                \n",
    "        origin_visit_emb = (self.pre_embedding(origin_visit) * mask_code).sum(dim=2)\n",
    "        next_visit_emb = (self.pre_embedding(next_visit) * next_mask_code).sum(dim=2)\n",
    "        # 위치 인코딩 및 Transformer 디코더 적용\n",
    "        if self.pe == 'time_feature':\n",
    "            time_feature = batch_data['time_feature'].to(self.device)\n",
    "            src = self.pos_encoder(origin_visit_emb, time_feature)\n",
    "        else:\n",
    "            src = self.pos_encoder(origin_visit_emb)\n",
    "        \n",
    "        seq_len = src.shape[1]\n",
    "        src_mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.uint8, device=self.device), diagonal=1)\n",
    "        output = self.transformer_decoder(src, attention_mask=src_mask)\n",
    "        output = self.decoder(output)\n",
    "        \n",
    "        output_batch, output_visit_num, output_dim = output.size()\n",
    "        next_visit_output_batch, next_visit_output_num, next_visit_output_dim = next_visit_emb.size()\n",
    "        \n",
    "        # print(output[:, :torch.,:])\n",
    "        temp_output = output.reshape(-1, output_dim)\n",
    "        temp_next_visit = next_visit_emb.reshape(-1, next_visit_output_dim)\n",
    "        final_visit = (output * mask_final).sum(dim=1)\n",
    "        # year_emb = torch.bmm(output.transpose(1,2), mask_final_year).transpose(1,2)[:,:2,:]\n",
    "        \n",
    "        # transformed_clinical = self.clinical_transform(clinical_tensor)\n",
    "        # mixed_output, mixed_cross_attn = self.cross_attn(year_emb, transformed_clinical, transformed_clinical)\n",
    "        # mixed_output = mixed_output[:,-1,:]\n",
    "        # mixed_final_emb = torch.cat((final_visit, mixed_output), dim=-1)\n",
    "        classification_result = self.classification_layer(final_visit)    \n",
    "        return temp_output, temp_next_visit, classification_result, final_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5890489-1f23-4a48-9e8b-73fbe5f90ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0005\n",
    "ninp = 64\n",
    "nhid = 256\n",
    "nlayer = 3\n",
    "gamma = 0.5\n",
    "model_name = 'no_center_total_label_no_clinical'\n",
    "pe = 'time_feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e25eb9d-006d-49ca-99e6-228e7d7414ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_1 = CustomTransformerModel(len(dtype_dict), ninp=ninp, nhead=4, nhid=nhid, nlayers=nlayer, dropout=0.1, device=device, pe=pe).to(device)\n",
    "# model_2 = CustomTransformerModel(len(dtype_dict), ninp=ninp, nhead=8, nhid=nhid, nlayers=nlayer, dropout=0.6, device=device, pe='fixed').to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_1.parameters(), lr=lr, weight_decay=1e-5)\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = FocalLoss(2, gamma=gamma)\n",
    "# cosine_loss = CosineSimilarityLoss()\n",
    "cosine_embedding_loss = nn.CosineEmbeddingLoss()\n",
    "# const_loss = ContrastiveLoss(temperature=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4143c27e-cff0-4359-8cbd-d5ef05e6ec16",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , Total loss: 1.8485 , cos_loss :  0.9826 , classification_loss : 0.8659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:03<06:00,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 , valid loss: 1.2361 , cos_loss :  0.96 , classification_loss : 0.2761\n",
      "Accuracy: 0.9204 , AUC:  0.5986 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 2 , Total loss: 1.176 , cos_loss :  0.947 , classification_loss : 0.229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:07<05:41,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 , valid loss: 1.1512 , cos_loss :  0.9358 , classification_loss : 0.2154\n",
      "Accuracy: 0.9204 , AUC:  0.6443 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 3 , Total loss: 1.1372 , cos_loss :  0.9299 , classification_loss : 0.2073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:10<05:39,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 , valid loss: 1.1176 , cos_loss :  0.9251 , classification_loss : 0.1925\n",
      "Accuracy: 0.9204 , AUC:  0.6595 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 4 , Total loss: 1.1246 , cos_loss :  0.9225 , classification_loss : 0.2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:13<05:31,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 , valid loss: 1.1101 , cos_loss :  0.9206 , classification_loss : 0.1896\n",
      "Accuracy: 0.9204 , AUC:  0.6764 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 5 , Total loss: 1.1198 , cos_loss :  0.9191 , classification_loss : 0.2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:17<05:25,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 , valid loss: 1.1101 , cos_loss :  0.9184 , classification_loss : 0.1917\n",
      "Accuracy: 0.9204 , AUC:  0.7098 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 6 , Total loss: 1.1176 , cos_loss :  0.9173 , classification_loss : 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:20<05:24,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 , valid loss: 1.1087 , cos_loss :  0.9172 , classification_loss : 0.1915\n",
      "Accuracy: 0.9204 , AUC:  0.7363 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 7 , Total loss: 1.115 , cos_loss :  0.9162 , classification_loss : 0.1988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:24<05:18,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 , valid loss: 1.1062 , cos_loss :  0.9164 , classification_loss : 0.1898\n",
      "Accuracy: 0.9204 , AUC:  0.7715 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 8 , Total loss: 1.1126 , cos_loss :  0.9153 , classification_loss : 0.1973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [00:27<05:17,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 , valid loss: 1.1044 , cos_loss :  0.9158 , classification_loss : 0.1886\n",
      "Accuracy: 0.9204 , AUC:  0.7732 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 9 , Total loss: 1.11 , cos_loss :  0.915 , classification_loss : 0.195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:31<05:11,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 , valid loss: 1.1026 , cos_loss :  0.9154 , classification_loss : 0.1872\n",
      "Accuracy: 0.9204 , AUC:  0.7685 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 10 , Total loss: 1.1117 , cos_loss :  0.9148 , classification_loss : 0.1969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:34<05:07,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 , valid loss: 1.1006 , cos_loss :  0.9152 , classification_loss : 0.1855\n",
      "Accuracy: 0.9204 , AUC:  0.7727 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 11 , Total loss: 1.1083 , cos_loss :  0.9145 , classification_loss : 0.1939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:37<05:05,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 , valid loss: 1.0982 , cos_loss :  0.9149 , classification_loss : 0.1833\n",
      "Accuracy: 0.9204 , AUC:  0.7718 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 12 , Total loss: 1.1079 , cos_loss :  0.9143 , classification_loss : 0.1936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [00:41<05:00,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 , valid loss: 1.0955 , cos_loss :  0.9148 , classification_loss : 0.1807\n",
      "Accuracy: 0.9204 , AUC:  0.77 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 13 , Total loss: 1.1048 , cos_loss :  0.9142 , classification_loss : 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:44<04:59,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 , valid loss: 1.0895 , cos_loss :  0.9148 , classification_loss : 0.1747\n",
      "Accuracy: 0.9204 , AUC:  0.769 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 14 , Total loss: 1.0975 , cos_loss :  0.9144 , classification_loss : 0.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [00:48<04:54,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 , valid loss: 1.079 , cos_loss :  0.915 , classification_loss : 0.164\n",
      "Accuracy: 0.9204 , AUC:  0.7677 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 15 , Total loss: 1.0812 , cos_loss :  0.9147 , classification_loss : 0.1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:51<04:52,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 , valid loss: 1.0784 , cos_loss :  0.9161 , classification_loss : 0.1623\n",
      "Accuracy: 0.9204 , AUC:  0.7299 , F1:  0.0 , Precision:  0.0 , recall:  0.0\n",
      "Epoch: 16 , Total loss: 1.0688 , cos_loss :  0.9157 , classification_loss : 0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:55<04:48,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 , valid loss: 1.0443 , cos_loss :  0.9163 , classification_loss : 0.128\n",
      "Accuracy: 0.954 , AUC:  0.7328 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 17 , Total loss: 1.0529 , cos_loss :  0.9157 , classification_loss : 0.1373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:58<04:44,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 , valid loss: 1.0411 , cos_loss :  0.916 , classification_loss : 0.1251\n",
      "Accuracy: 0.954 , AUC:  0.7655 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 18 , Total loss: 1.0529 , cos_loss :  0.9152 , classification_loss : 0.1377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [01:02<04:43,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 , valid loss: 1.0405 , cos_loss :  0.9157 , classification_loss : 0.1249\n",
      "Accuracy: 0.954 , AUC:  0.7703 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 19 , Total loss: 1.0518 , cos_loss :  0.915 , classification_loss : 0.1369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [01:05<04:38,  3.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 , valid loss: 1.0408 , cos_loss :  0.9157 , classification_loss : 0.1251\n",
      "Accuracy: 0.954 , AUC:  0.7714 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 20 , Total loss: 1.0491 , cos_loss :  0.9147 , classification_loss : 0.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [01:08<04:36,  3.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 , valid loss: 1.0393 , cos_loss :  0.9156 , classification_loss : 0.1237\n",
      "Accuracy: 0.954 , AUC:  0.7719 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 21 , Total loss: 1.0482 , cos_loss :  0.9149 , classification_loss : 0.1334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [01:12<04:35,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 , valid loss: 1.0393 , cos_loss :  0.9155 , classification_loss : 0.1238\n",
      "Accuracy: 0.954 , AUC:  0.772 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 22 , Total loss: 1.0474 , cos_loss :  0.9148 , classification_loss : 0.1326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [01:15<04:30,  3.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 , valid loss: 1.0432 , cos_loss :  0.9155 , classification_loss : 0.1277\n",
      "Accuracy: 0.954 , AUC:  0.7699 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 23 , Total loss: 1.0497 , cos_loss :  0.9147 , classification_loss : 0.135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [01:19<04:27,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 , valid loss: 1.0396 , cos_loss :  0.9153 , classification_loss : 0.1242\n",
      "Accuracy: 0.954 , AUC:  0.7702 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 24 , Total loss: 1.0482 , cos_loss :  0.9144 , classification_loss : 0.1337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:23<04:29,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 , valid loss: 1.0395 , cos_loss :  0.9153 , classification_loss : 0.1242\n",
      "Accuracy: 0.954 , AUC:  0.7709 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 25 , Total loss: 1.049 , cos_loss :  0.9147 , classification_loss : 0.1344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [01:27<04:40,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 , valid loss: 1.0388 , cos_loss :  0.9152 , classification_loss : 0.1236\n",
      "Accuracy: 0.954 , AUC:  0.7713 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 26 , Total loss: 1.0496 , cos_loss :  0.9145 , classification_loss : 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [01:31<04:42,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 , valid loss: 1.0397 , cos_loss :  0.9153 , classification_loss : 0.1245\n",
      "Accuracy: 0.954 , AUC:  0.7694 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 27 , Total loss: 1.0474 , cos_loss :  0.9145 , classification_loss : 0.133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [01:35<04:43,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 , valid loss: 1.0394 , cos_loss :  0.9152 , classification_loss : 0.1242\n",
      "Accuracy: 0.954 , AUC:  0.769 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 28 , Total loss: 1.0521 , cos_loss :  0.9145 , classification_loss : 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [01:39<04:46,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 , valid loss: 1.0398 , cos_loss :  0.9152 , classification_loss : 0.1246\n",
      "Accuracy: 0.954 , AUC:  0.7705 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 29 , Total loss: 1.0495 , cos_loss :  0.9144 , classification_loss : 0.1351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [01:43<04:43,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 , valid loss: 1.0464 , cos_loss :  0.9152 , classification_loss : 0.1312\n",
      "Accuracy: 0.954 , AUC:  0.7712 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 30 , Total loss: 1.0489 , cos_loss :  0.9142 , classification_loss : 0.1347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [01:47<04:35,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 , valid loss: 1.0395 , cos_loss :  0.9151 , classification_loss : 0.1244\n",
      "Accuracy: 0.954 , AUC:  0.767 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 31 , Total loss: 1.0488 , cos_loss :  0.9143 , classification_loss : 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [01:50<04:20,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 , valid loss: 1.0392 , cos_loss :  0.9151 , classification_loss : 0.1241\n",
      "Accuracy: 0.954 , AUC:  0.7631 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 32 , Total loss: 1.0486 , cos_loss :  0.9144 , classification_loss : 0.1343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [01:54<04:08,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 , valid loss: 1.0595 , cos_loss :  0.9152 , classification_loss : 0.1443\n",
      "Accuracy: 0.954 , AUC:  0.7696 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 33 , Total loss: 1.0494 , cos_loss :  0.9148 , classification_loss : 0.1346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [01:57<04:01,  3.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 , valid loss: 1.0413 , cos_loss :  0.9154 , classification_loss : 0.1259\n",
      "Accuracy: 0.954 , AUC:  0.7554 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 34 , Total loss: 1.0432 , cos_loss :  0.9148 , classification_loss : 0.1285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [02:00<03:53,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 , valid loss: 1.0428 , cos_loss :  0.9155 , classification_loss : 0.1273\n",
      "Accuracy: 0.954 , AUC:  0.7453 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 35 , Total loss: 1.0429 , cos_loss :  0.9149 , classification_loss : 0.1281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [02:04<03:48,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 , valid loss: 1.0434 , cos_loss :  0.9158 , classification_loss : 0.1276\n",
      "Accuracy: 0.954 , AUC:  0.7492 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 36 , Total loss: 1.0385 , cos_loss :  0.9152 , classification_loss : 0.1233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [02:07<03:43,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 , valid loss: 1.048 , cos_loss :  0.9163 , classification_loss : 0.1318\n",
      "Accuracy: 0.954 , AUC:  0.7507 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 37 , Total loss: 1.0328 , cos_loss :  0.9158 , classification_loss : 0.117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [02:11<03:40,  3.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 , valid loss: 1.059 , cos_loss :  0.9167 , classification_loss : 0.1423\n",
      "Accuracy: 0.944 , AUC:  0.7583 , F1:  0.5631 , Precision:  0.7436 , recall:  0.4531\n",
      "Epoch: 38 , Total loss: 1.0253 , cos_loss :  0.9162 , classification_loss : 0.1091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [02:14<03:38,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 , valid loss: 1.0598 , cos_loss :  0.9176 , classification_loss : 0.1422\n",
      "Accuracy: 0.949 , AUC:  0.763 , F1:  0.5859 , Precision:  0.8286 , recall:  0.4531\n",
      "Epoch: 39 , Total loss: 1.0204 , cos_loss :  0.9171 , classification_loss : 0.1033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [02:18<03:34,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 , valid loss: 1.0738 , cos_loss :  0.9182 , classification_loss : 0.1556\n",
      "Accuracy: 0.9328 , AUC:  0.7713 , F1:  0.5179 , Precision:  0.6042 , recall:  0.4531\n",
      "Epoch: 40 , Total loss: 1.0114 , cos_loss :  0.9173 , classification_loss : 0.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [02:22<03:32,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 , valid loss: 1.085 , cos_loss :  0.9186 , classification_loss : 0.1664\n",
      "Accuracy: 0.9204 , AUC:  0.7538 , F1:  0.4754 , Precision:  0.5 , recall:  0.4531\n",
      "Epoch: 41 , Total loss: 1.0081 , cos_loss :  0.9177 , classification_loss : 0.0904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [02:25<03:28,  3.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 , valid loss: 1.0819 , cos_loss :  0.9195 , classification_loss : 0.1624\n",
      "Accuracy: 0.954 , AUC:  0.7541 , F1:  0.5934 , Precision:  1.0 , recall:  0.4219\n",
      "Epoch: 42 , Total loss: 0.9976 , cos_loss :  0.9184 , classification_loss : 0.0792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [02:28<03:22,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 , valid loss: 1.0762 , cos_loss :  0.9199 , classification_loss : 0.1564\n",
      "Accuracy: 0.9428 , AUC:  0.7811 , F1:  0.54 , Precision:  0.75 , recall:  0.4219\n",
      "Epoch: 43 , Total loss: 0.9881 , cos_loss :  0.9188 , classification_loss : 0.0693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [02:32<03:19,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 , valid loss: 1.0731 , cos_loss :  0.9199 , classification_loss : 0.1532\n",
      "Accuracy: 0.9465 , AUC:  0.7365 , F1:  0.5657 , Precision:  0.8 , recall:  0.4375\n",
      "Epoch: 44 , Total loss: 0.9803 , cos_loss :  0.9189 , classification_loss : 0.0614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [02:35<03:14,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 , valid loss: 1.0766 , cos_loss :  0.9204 , classification_loss : 0.1562\n",
      "Accuracy: 0.944 , AUC:  0.7727 , F1:  0.5631 , Precision:  0.7436 , recall:  0.4531\n",
      "Epoch: 45 , Total loss: 0.973 , cos_loss :  0.9193 , classification_loss : 0.0537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:39<03:11,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 , valid loss: 1.0906 , cos_loss :  0.9206 , classification_loss : 0.17\n",
      "Accuracy: 0.9428 , AUC:  0.7519 , F1:  0.566 , Precision:  0.7143 , recall:  0.4688\n",
      "Epoch: 46 , Total loss: 0.9729 , cos_loss :  0.9196 , classification_loss : 0.0533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [02:42<03:18,  3.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 , valid loss: 1.0673 , cos_loss :  0.9206 , classification_loss : 0.1466\n",
      "Accuracy: 0.9453 , AUC:  0.774 , F1:  0.551 , Precision:  0.7941 , recall:  0.4219\n",
      "Early stopping triggered at epoch 15\n",
      "Best Combined Score (AUC): 0.5934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 얼리 스타핑 설정\n",
    "num_epochs = 100\n",
    "patience = 30\n",
    "best_loss = float(\"inf\")\n",
    "counter = 0\n",
    "epoch_temp = 0\n",
    "\n",
    "best_f1 = 0.0\n",
    "best_combined_score = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "view_total_loss = []\n",
    "view_cos_loss = []\n",
    "view_classi_loss = []\n",
    "\n",
    "cos_lambda = 1\n",
    "classi_lambda = 1\n",
    "const_lambda = 1\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model_1.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    total_cos_loss = 0\n",
    "    total_classi_loss = 0\n",
    "    total_const_loss = 0\n",
    "    # key_per_sample, origin_visit, origin_mask, origin_mask_code, origin_mask_final, next_visit, next_mask, next_mask_code, next_mask_final, label_per_sample\n",
    "    for batch_data in train_loader:\n",
    "        tr_labels = batch_data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output_1, next_visit_output_1, final_visit_classification_1, final_visit_1 = model_1(batch_data)\n",
    "        y = torch.ones(output_1.size(0), dtype=torch.float, device=device)\n",
    "        y = y.to(device)   \n",
    "        cosine_loss_mean_1 = cosine_embedding_loss(output_1, next_visit_output_1, y)\n",
    "        classification_loss_1 = criterion(final_visit_classification_1.squeeze(), tr_labels.long())\n",
    "        loss = (cos_lambda * cosine_loss_mean_1) + (classi_lambda * classification_loss_1)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "        total_cos_loss += (cosine_loss_mean_1.item())\n",
    "        total_classi_loss += (classification_loss_1.item())\n",
    "        # total_const_loss += train_const_loss.item()\n",
    "\n",
    "        view_total_loss.append(total_train_loss)\n",
    "        view_cos_loss.append(total_cos_loss)\n",
    "        view_classi_loss.append(total_classi_loss)\n",
    "\n",
    "    # 평균 손실 계산\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_cos_loss = total_cos_loss / len(train_loader)\n",
    "    avg_classi_loss = total_classi_loss / len(train_loader)\n",
    "\n",
    "    print(\"Epoch:\", epoch+1, \", Total loss:\", round(avg_train_loss, 4), \", cos_loss : \",\\\n",
    "          round(avg_cos_loss, 4), \", classification_loss :\",round(avg_classi_loss, 4))\n",
    "\n",
    "    model_1.eval()\n",
    "    total_val_loss = 0\n",
    "    total_val_cos_loss = 0\n",
    "    total_val_classi_loss = 0\n",
    "    total_val_const_loss = 0\n",
    "\n",
    "    val_labels_list = []\n",
    "    val_predictions_list = []\n",
    "    val_probabilities_list = []\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_data in valid_loader:\n",
    "            val_labels = batch_data['label'].to(device)\n",
    "            val_output_1, val_next_visit_output_1, val_final_visit_classification_1, val_final_visit_1 = model_1(batch_data)\n",
    "            \n",
    "            y_val = torch.ones(val_output_1.size(0), dtype=torch.float, device=device) \n",
    "            val_cosine_loss_mean_1 = cosine_embedding_loss(val_output_1, val_next_visit_output_1, y_val)\n",
    "            \n",
    "            classification_loss_val_1 = criterion(val_final_visit_classification_1.squeeze(), val_labels.long())            \n",
    "\n",
    "            val_loss = (cos_lambda * val_cosine_loss_mean_1) + (classi_lambda * classification_loss_val_1) \n",
    "            \n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_cos_loss += (val_cosine_loss_mean_1.item())\n",
    "            total_val_classi_loss += (classification_loss_val_1.item())\n",
    "            # total_val_const_loss += val_const_loss.item()\n",
    "\n",
    "            val_probs = F.softmax(val_final_visit_classification_1)\n",
    "            val_predictions = torch.max(val_probs, 1)[1].view((len(val_labels),))\n",
    "\n",
    "            val_labels_list.extend(val_labels.view(-1).cpu().numpy())\n",
    "            val_predictions_list.extend(val_predictions.cpu().numpy())\n",
    "            \n",
    "            ########\n",
    "            val_probabilities_list.extend(val_probs[:,1].cpu().numpy())\n",
    "            ######## \n",
    "            \n",
    "            \n",
    "        avg_val_loss = total_val_loss / len(valid_loader)\n",
    "        avg_val_cos_loss = total_val_cos_loss / len(valid_loader)\n",
    "        avg_val_classi_loss = total_val_classi_loss / len(valid_loader)\n",
    "\n",
    "    # 성능 지표 계산\n",
    "    accuracy = accuracy_score(val_labels_list, val_predictions_list)\n",
    "    auc = roc_auc_score(val_labels_list, val_probabilities_list)\n",
    "    f1 = f1_score(val_labels_list, val_predictions_list)\n",
    "    precision = precision_score(val_labels_list,val_predictions_list)\n",
    "    recall = recall_score(val_labels_list, val_predictions_list)\n",
    "\n",
    "    print(\"Epoch:\", epoch+1, \", valid loss:\", round(avg_val_loss, 4), \", cos_loss : \",\\\n",
    "          round(avg_val_cos_loss, 4), \", classification_loss :\",round(avg_val_classi_loss, 4))\n",
    "    print(\"Accuracy:\", round(accuracy,4), \", AUC: \", round(auc,4), \", F1: \", round(f1,4), \", Precision: \", round(precision,4), \", recall: \", round(recall,4))\n",
    "\n",
    "    current_auc = roc_auc_score(val_labels_list, val_probabilities_list)\n",
    "    current_f1 = f1_score(val_labels_list, val_predictions_list)\n",
    "    current_combined_score = current_f1\n",
    "\n",
    "    # 모델 저장 경로 설정\n",
    "    model_save_path = f'results'\n",
    "    date_dir = datetime.today().strftime(\"%Y%m%d\")\n",
    "    model_time =  datetime.today().strftime(\"%H%M%S\")\n",
    "    # 학습률과 분류 가중치를 파일명에 포함시키기 위한 문자열 포맷\n",
    "    model_filename_format = f'model_lr{lr}_classi{classi_lambda}_dim{ninp}_hid{nhid}_layer{nlayer}_epoch{{epoch}}_{{model}}_{{pe}}_{{gamma}}_{model_time}.pth'\n",
    "\n",
    "    # 모델 저장 폴더가 없으면 생성\n",
    "    os.makedirs(os.path.join(model_save_path, date_dir), exist_ok=True)\n",
    "\n",
    "    if current_combined_score > best_combined_score:\n",
    "        best_combined_score = current_combined_score\n",
    "        best_epoch = epoch\n",
    "        counter = 0\n",
    "        # 모델 저장 경로와 파일명을 결합하여 전체 파일 경로 생성\n",
    "        model_1_save_path = os.path.join(model_save_path, date_dir, model_filename_format.format(epoch=best_epoch, model=model_name, pe=pe, gamma=gamma))\n",
    "        # 모델 저장\n",
    "        torch.save(model_1.state_dict(), f'{model_1_save_path}')\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    if counter >= patience:\n",
    "        print(\"Early stopping triggered at epoch {}\".format(best_epoch))\n",
    "        print(f\"Best Combined Score (AUC): {best_combined_score:.4f}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ea59b82a-545f-4d8a-9d7c-b4531f4f09a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  5.01it/s]\n"
     ]
    }
   ],
   "source": [
    "total_te_loss = 0\n",
    "total_te_cos_loss = 0\n",
    "total_te_classi_loss = 0\n",
    "total_te_const_loss = 0\n",
    "\n",
    "te_labels_list = []\n",
    "te_predictions_list = []\n",
    "te_probabilities_list = []\n",
    "\n",
    "model_1_path = model_1_save_path\n",
    "\n",
    "model_1.load_state_dict(torch.load(model_1_path))\n",
    "\n",
    "model_1.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, batch_data in enumerate(tqdm(test_loader)):\n",
    "        te_labels = batch_data['label'].to(device)\n",
    "        te_output_1, te_next_visit_output_1, te_final_visit_classification_1, te_final_visit_1 = model_1(batch_data)\n",
    "        y_te = torch.ones(te_output_1.size(0), dtype=torch.float, device=device)\n",
    "        \n",
    "        if batch_idx == 0:\n",
    "            test_visit_embedding = te_final_visit_1.detach().cpu().numpy()\n",
    "            test_label_numpy = te_labels.detach().cpu().numpy()\n",
    "        else:\n",
    "            add_visit_embedding = te_final_visit_1.detach().cpu().numpy()\n",
    "            add_label_numpy = te_labels.detach().cpu().numpy()\n",
    "            test_visit_embedding = np.concatenate((test_visit_embedding, add_visit_embedding), axis=0)\n",
    "            test_label_numpy = np.concatenate((test_label_numpy, add_label_numpy))\n",
    "\n",
    "        te_cosine_loss_mean_1 = cosine_embedding_loss(te_output_1, te_next_visit_output_1, y_te)\n",
    "        classification_loss_te_1 = criterion(te_final_visit_classification_1.squeeze(), te_labels.long())\n",
    "        te_loss = (cos_lambda * te_cosine_loss_mean_1) + (classi_lambda * classification_loss_te_1) \n",
    "\n",
    "        total_te_loss += te_loss.item()\n",
    "        total_te_cos_loss += (te_cosine_loss_mean_1.item())\n",
    "        total_te_classi_loss += (classification_loss_te_1.item())\n",
    "\n",
    "        te_probs = F.softmax(te_final_visit_classification_1)\n",
    "        te_predictions = torch.max(te_probs, 1)[1].view((len(te_labels),))\n",
    "        \n",
    "        te_labels_list.extend(te_labels.view(-1).cpu().numpy())\n",
    "        te_predictions_list.extend(te_predictions.cpu().numpy())\n",
    "        te_probabilities_list.extend(te_probs[:,1].cpu().numpy())\n",
    "\n",
    "    avg_te_loss = total_te_loss / len(test_loader)\n",
    "    avg_te_cos_loss = total_te_cos_loss / len(test_loader)\n",
    "    avg_te_classi_loss = total_te_classi_loss / len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f87c3121-1152-41b2-8f8c-b47b01139157",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 1.0603 , cos_loss :  0.9183 , classification_loss : 0.142\n",
      "Accuracy: 0.9502 , AUC:  0.7388 , F1:  0.5455 , Precision:  1.0 , recall:  0.375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([740,  64]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 성능 지표 계산\n",
    "accuracy = accuracy_score(te_labels_list, te_predictions_list)\n",
    "auc = roc_auc_score(te_labels_list, te_probabilities_list)\n",
    "f1 = f1_score(te_labels_list, te_predictions_list)\n",
    "precision = precision_score(te_labels_list,te_predictions_list)\n",
    "recall = recall_score(te_labels_list, te_predictions_list)\n",
    "\n",
    "print(\"test loss:\", round(avg_te_loss, 4), \", cos_loss : \", round(avg_te_cos_loss, 4),\n",
    "      \", classification_loss :\",round(avg_te_classi_loss, 4), \n",
    "      # \", contrastive_loss : \", round(avg_te_const_loss,4)\n",
    "     )\n",
    "print(\"Accuracy:\", round(accuracy,4), \", AUC: \", round(auc,4), \", F1: \", round(f1,4), \", Precision: \", round(precision,4), \", recall: \", round(recall,4))\n",
    "\n",
    "np.unique(te_labels_list,  return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59a45dbf-6a08-401e-a279-411c1e99c094",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './logs'\n",
    "logs = f'model_lr{lr}_classi{classi_lambda}_dim{ninp}_hid{nhid}_layer{nlayer}_epoch{{epoch}}_{{model}}_{{pe}}_{model_time}.txt'\n",
    "os.makedirs(os.path.join(log_path, date_dir), exist_ok=True)\n",
    "\n",
    "results = [accuracy, auc, f1, precision, recall]\n",
    "cm = confusion_matrix(te_labels_list, te_predictions_list)\n",
    "with open(os.path.join(log_path, date_dir, logs.format(epoch=best_epoch, model=model_name, pe=pe)), 'w') as f:\n",
    "    f.write(logs.format(epoch=best_epoch, model=model_name, pe=pe))\n",
    "    f.write('\\n')\n",
    "    f.write(str(results))\n",
    "    f.write('\\n')\n",
    "    f.write(str(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d01e7e3b-c3e6-4813-8eeb-dfc111a65c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[740,   0],\n",
       "       [ 40,  24]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(te_labels_list, te_predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "afafd27a-940d-442a-86be-3c3211185eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2cdc3fad-8031-4d34-8d4c-0de81b0fd2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne_model = TSNE(n_components=2)\n",
    "reduction_emb = tsne_model.fit_transform(test_visit_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "412cc221-acb8-442c-8824-797f2f5dc421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for g in np.unique(test_label_numpy):\n",
    "    ix = np.where(test_label_numpy == g)\n",
    "    ax.scatter(reduction_emb[ix, 0], reduction_emb[ix, 1], label = g, s = 10)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4bb0e-3641-48cb-ac47-4e79a7ae9a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
